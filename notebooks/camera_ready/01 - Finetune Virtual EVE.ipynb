{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "import torch\n",
    "import wandb\n",
    "from sdofm import utils\n",
    "from sdofm.datasets import SDOMLDataModule, DegradedSDOMLDataModule\n",
    "from sdofm.pretraining import MAE, SAMAE\n",
    "from sdofm.finetuning import Autocalibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import omegaconf\n",
    "\n",
    "cfg = omegaconf.OmegaConf.load(\"../../experiments/finetune_32.2M_mae_virtualeve.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[* CACHE SYSTEM *] Found cached index data in /mnt/sdoml/cache/aligndata_AIA_FULL_12min.csv.\n",
      "[* CACHE SYSTEM *] Found cached normalization data in /mnt/sdoml/cache/normalizations_AIA_FULL_12min.json.\n",
      "[* CACHE SYSTEM *] Found cached HMI mask data in /mnt/sdoml/cache/hmi_mask_512x512.npy.\n"
     ]
    }
   ],
   "source": [
    "data_module = SDOMLDataModule(\n",
    "    hmi_path=None,\n",
    "    aia_path=os.path.join(\n",
    "        cfg.data.sdoml.base_directory, cfg.data.sdoml.sub_directory.aia\n",
    "    ),\n",
    "    eve_path=None,\n",
    "    components=cfg.data.sdoml.components,\n",
    "    wavelengths=cfg.data.sdoml.wavelengths,\n",
    "    ions=cfg.data.sdoml.ions,\n",
    "    frequency=cfg.data.sdoml.frequency,\n",
    "    batch_size=cfg.model.opt.batch_size,\n",
    "    num_workers=cfg.data.num_workers,\n",
    "    val_months=cfg.data.month_splits.val,\n",
    "    test_months=cfg.data.month_splits.test,\n",
    "    holdout_months=cfg.data.month_splits.holdout,\n",
    "    cache_dir=os.path.join(\n",
    "        cfg.data.sdoml.base_directory, cfg.data.sdoml.sub_directory.cache\n",
    "    ),\n",
    "    min_date=cfg.data.min_date,\n",
    "    max_date=cfg.data.max_date,\n",
    "    num_frames=1,\n",
    ")\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(\n",
    "        self,\n",
    "        # Backbone parameters\n",
    "        img_size: int = 512,\n",
    "        patch_size: int = 16,\n",
    "        embed_dim: int = 128,\n",
    "        num_frames: int = 5,\n",
    "        # Neck parameters\n",
    "        num_neck_filters: int = 32,\n",
    "        # Head parameters\n",
    "        # d_input=None,\n",
    "        cnn_model: str = \"efficientnet_b3\",\n",
    "        lr_linear: float = 0.01,\n",
    "        lr_cnn: float = 0.0001,\n",
    "        cnn_dp: float = 0.75,\n",
    "        epochs_linear: int = 50,\n",
    "        d_output=None,\n",
    "        eve_norm=None,\n",
    "        # for finetuning\n",
    "        backbone: object = None,\n",
    "        freeze_encoder: bool = True,\n",
    "        # all else\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.eve_norm = eve_norm\n",
    "\n",
    "        self.backbone = backbone\n",
    "        self.encoder = PrithviEncoder(self.backbone)\n",
    "\n",
    "        if freeze_encoder:\n",
    "            self.encoder.eval()\n",
    "            for param in self.encoder.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        num_tokens = img_size // patch_size\n",
    "\n",
    "        # NECK\n",
    "        self.decoder = ConvTransformerTokensToEmbeddingNeck(\n",
    "            embed_dim=embed_dim,\n",
    "            output_embed_dim=num_neck_filters,\n",
    "            Hp=num_tokens,\n",
    "            Wp=num_tokens,\n",
    "            drop_cls_token=True,\n",
    "            num_frames=num_frames,\n",
    "        )\n",
    "\n",
    "        # HEAD\n",
    "        self.head = HybridIrradianceModel(\n",
    "            # virtual eve\n",
    "            d_input=num_neck_filters,\n",
    "            d_output=d_output,\n",
    "            eve_norm=eve_norm,\n",
    "            # from config\n",
    "            cnn_model=cnn_model,\n",
    "            lr_linear=lr_linear,\n",
    "            lr_cnn=lr_cnn,\n",
    "            cnn_dp=cnn_dp,\n",
    "            epochs_linear=epochs_linear,\n",
    "        )\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        imgs, eve = batch\n",
    "        x = self.encoder(imgs[:, :9, :, :, :])\n",
    "        y_hat = self.head(self.decoder(x))\n",
    "        loss = self.head.loss_func(y_hat, eve[:, :38])\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        imgs, eve = batch\n",
    "        x = self.encoder(imgs[:, :9, :, :, :])\n",
    "        y_hat = self.head(self.decoder(x))\n",
    "        loss = self.head.loss_func(y_hat, eve[:, :38])\n",
    "        self.log(\"val_loss\", loss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
