{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instrument Degradation Prediction from Pretrained Embeddings\n",
    "\n",
    "![Figure 1: Instrument Degrad with latents](assets/architecture_diags_degrad.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import omegaconf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = omegaconf.OmegaConf.load(\"finetune_degrad_config.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[* CACHE SYSTEM *] Found cached index data in /mnt/sdoml/cache/aligndata_AIA_FULL_12min.csv.\n",
      "[* CACHE SYSTEM *] Found cached normalization data in /mnt/sdoml/cache/normalizations_AIA_FULL_12min.json.\n",
      "[* CACHE SYSTEM *] Found cached HMI mask data in /mnt/sdoml/cache/hmi_mask_512x512.npy.\n"
     ]
    }
   ],
   "source": [
    "from sdofm.datasets import DegradedSDOMLDataModule\n",
    "data_module = DegradedSDOMLDataModule(\n",
    "    hmi_path=None,\n",
    "    aia_path=os.path.join(\n",
    "        cfg.data.sdoml.base_directory, cfg.data.sdoml.sub_directory.aia\n",
    "    ),\n",
    "    eve_path=None,\n",
    "    components=cfg.data.sdoml.components,\n",
    "    wavelengths=cfg.data.sdoml.wavelengths,\n",
    "    ions=cfg.data.sdoml.ions,\n",
    "    frequency=cfg.data.sdoml.frequency,\n",
    "    batch_size=cfg.model.opt.batch_size,\n",
    "    num_workers=cfg.data.num_workers,\n",
    "    val_months=cfg.data.month_splits.val,\n",
    "    test_months=cfg.data.month_splits.test,\n",
    "    holdout_months=cfg.data.month_splits.holdout,\n",
    "    cache_dir=os.path.join(\n",
    "        cfg.data.sdoml.base_directory,\n",
    "        cfg.data.sdoml.sub_directory.cache,\n",
    "    ),\n",
    "    min_date=cfg.data.min_date,\n",
    "    max_date=cfg.data.max_date,\n",
    "    num_frames=cfg.data.num_frames,\n",
    ")\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sdofm import BaseModule\n",
    "from sdofm.models import (\n",
    "    Autocalibration13Head,\n",
    "    ConvTransformerTokensToEmbeddingNeck,\n",
    "    MaskedAutoencoderViT3D,\n",
    "    WrapEncoder,\n",
    "    SolarAwareMaskedAutoencoderViT3D,\n",
    ")\n",
    "\n",
    "\n",
    "def heteroscedastic_loss(output, gt_output, reduction):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        output: NN output values, tensor of shape 2, batch_size, n_channels.\n",
    "        where the first dimension contains the mean values and the second\n",
    "        dimension contains the log_var\n",
    "        gt_output: groundtruth values. tensor of shape batch_size, n_channels\n",
    "        reduction: if mean, the loss is averaged across the third dimension,\n",
    "        if summ the loss is summed across the third dimension, if None any\n",
    "        aggregation is performed\n",
    "\n",
    "    Returns:\n",
    "        tensor of size n_channels if reduction is None or tensor of size 0\n",
    "        if reduction is mean or sum\n",
    "\n",
    "    \"\"\"\n",
    "    precision = torch.exp(-output[1])\n",
    "    batch_size = output[0].shape[0]\n",
    "    loss = (\n",
    "        torch.sum(precision * (gt_output - output[0]) ** 2.0 + output[1], 0)\n",
    "        / batch_size\n",
    "    )\n",
    "    if reduction == \"mean\":\n",
    "        return loss.mean()\n",
    "    elif reduction == \"sum\":\n",
    "        return loss.sum()\n",
    "    elif reduction is None:\n",
    "        return loss\n",
    "    else:\n",
    "        raise ValueError(\"Aggregation can only be None, mean or sum.\")\n",
    "\n",
    "\n",
    "class HeteroscedasticLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Heteroscedastic loss\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, reduction=\"mean\"):\n",
    "        super(HeteroscedasticLoss, self).__init__()\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        return heteroscedastic_loss(output, target, reduction=self.reduction)\n",
    "\n",
    "\n",
    "class Autocalibration(BaseModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        # Backbone parameters\n",
    "        img_size=512,\n",
    "        patch_size=16,\n",
    "        embed_dim=128,\n",
    "        num_frames=5,\n",
    "        # Neck parameters\n",
    "        num_neck_filters: int = 32,\n",
    "        # Head parameters\n",
    "        output_dim: int = 1,\n",
    "        loss: str = \"mse\",\n",
    "        freeze_encoder: bool = True,\n",
    "        # if finetuning\n",
    "        backbone: object = None,\n",
    "        # all else\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.backbone = backbone\n",
    "        self.encoder = WrapEncoder(self.backbone)\n",
    "\n",
    "        if freeze_encoder:\n",
    "            self.encoder.eval()\n",
    "            for param in self.encoder.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        num_tokens = img_size // patch_size\n",
    "\n",
    "        # NECK\n",
    "        self.decoder = ConvTransformerTokensToEmbeddingNeck(\n",
    "            embed_dim=embed_dim,\n",
    "            output_embed_dim=num_neck_filters,\n",
    "            Hp=num_tokens,\n",
    "            Wp=num_tokens,\n",
    "            drop_cls_token=True,\n",
    "            num_frames=num_frames,\n",
    "        )\n",
    "\n",
    "        # HEAD\n",
    "        self.head = Autocalibration13Head(\n",
    "            [num_neck_filters, img_size, img_size], output_dim\n",
    "        )\n",
    "\n",
    "        # set loss function\n",
    "        match loss:\n",
    "            case \"mse\":\n",
    "                self.loss_function = nn.MSELoss()\n",
    "            case \"heteroscedastic\":\n",
    "                self.loss_function = HeteroscedasticLoss()\n",
    "            case _:\n",
    "                raise NotImplementedError(f\"Loss function {loss} not implemented\")\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        degraded_img, degrad_factor, orig_img = batch\n",
    "        x = self.encoder(degraded_img)\n",
    "        # print(\"Autocal training: encoder out dim\", x.shape)\n",
    "        # x_hat = self.autoencoder.unpatchify(x_hat)\n",
    "        x = self.decoder(x)\n",
    "        # print(\"Autocal training: decoder out dim\", x.shape)\n",
    "        y_hat = self.head(x)\n",
    "        loss = self.loss_function(y_hat[0, :, :], degrad_factor)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        degraded_img, degrad_factor, orig_img = batch\n",
    "        x = self.encoder(degraded_img)\n",
    "        # x_hat = self.autoencoder.unpatchify(x_hat)\n",
    "        y_hat = self.head(self.decoder(x))\n",
    "        loss = self.loss_function(y_hat[0, :, :], degrad_factor)\n",
    "        self.log(\"val_loss\", loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using <class 'sdofm.datasets.SDOML.SDOMLDataModule'> Data Class\n",
      "[* CACHE SYSTEM *] Found cached index data in /mnt/sdoml/cache/aligndata_AIA_FULL_12min.csv.\n",
      "[* CACHE SYSTEM *] Found cached normalization data in /mnt/sdoml/cache/normalizations_AIA_FULL_12min.json.\n",
      "[* CACHE SYSTEM *] Found cached HMI mask data in /mnt/sdoml/cache/hmi_mask_512x512.npy.\n",
      "Loading checkpoint...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from pretrain import Pretrainer\n",
    "MAE = Pretrainer(cfg, logger=None, is_backbone=True)\n",
    "backbone = MAE.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autocalibration initialising\n",
      "input_channels: 32\n",
      "[32, 512, 512]\n",
      "cnn_output_dim: 401408\n"
     ]
    }
   ],
   "source": [
    "\n",
    "backbone_params = {}\n",
    "backbone_params[\"img_size\"] = cfg.model.mae.img_size\n",
    "backbone_params[\"patch_size\"] = cfg.model.mae.patch_size\n",
    "backbone_params[\"embed_dim\"] = cfg.model.mae.embed_dim\n",
    "backbone_params[\"num_frames\"] = cfg.model.mae.num_frames\n",
    "\n",
    "model = Autocalibration(\n",
    "    # backbone\n",
    "    **backbone_params,\n",
    "    # backbone\n",
    "    backbone=backbone,\n",
    "    hyperparam_ignore=[\"backbone\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 4 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=4)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name          | Type                                 | Params | Mode \n",
      "-------------------------------------------------------------------------------\n",
      "0 | backbone      | MAE                                  | 104 M  | eval \n",
      "1 | encoder       | WrapEncoder                          | 104 M  | eval \n",
      "2 | decoder       | ConvTransformerTokensToEmbeddingNeck | 78.1 K | train\n",
      "3 | head          | Autocalibration13Head                | 895 K  | train\n",
      "4 | loss_function | MSELoss                              | 0      | train\n",
      "-------------------------------------------------------------------------------\n",
      "973 K     Trainable params\n",
      "104 M     Non-trainable params\n",
      "105 M     Total params\n",
      "422.108   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8993900e1e3492d85621722b251aa30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1, 9])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b542361fef5c47aa980ec6e4a13c022a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lightning.pytorch import Trainer \n",
    "os.environ['PJRT_DEVICE'] = 'GPU'\n",
    "trainer = Trainer(max_epochs=2, precision=32)\n",
    "trainer.fit(model=model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
