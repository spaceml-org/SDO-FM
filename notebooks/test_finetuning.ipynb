{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "import torch\n",
    "import wandb\n",
    "from sdofm import utils\n",
    "from sdofm.datasets import SDOMLDataModule, DegradedSDOMLDataModule\n",
    "from sdofm.pretraining import MAE, SAMAE\n",
    "from sdofm.finetuning import Autocalibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import omegaconf\n",
    "\n",
    "cfg = omegaconf.OmegaConf.load(\"../experiments/finetune_tiny.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sdofm.utils import flatten_dict\n",
    "# import yaml\n",
    "\n",
    "# data = flatten_dict(cfg, sep=\"___\")\n",
    "# with open('testingout.yaml', 'w+') as outfile:\n",
    "#     yaml.dump(data, outfile, default_flow_style=False)\n",
    "# outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from omegaconf import OmegaConf\n",
    "# OmegaConf.save(config, \"testout.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[* CACHE SYSTEM *] Found cached index data in /mnt/sdoml/cache/aligndata_AIA_FULL_12min.csv.\n",
      "[* CACHE SYSTEM *] Found cached normalization data in /mnt/sdoml/cache/normalizations_AIA_FULL_12min.json.\n",
      "[* CACHE SYSTEM *] Found cached HMI mask data in /mnt/sdoml/cache/hmi_mask_512x512.npy.\n"
     ]
    }
   ],
   "source": [
    "degraded_data_module = DegradedSDOMLDataModule(\n",
    "    hmi_path=None,\n",
    "    aia_path=os.path.join(\n",
    "        cfg.data.sdoml.base_directory, cfg.data.sdoml.sub_directory.aia\n",
    "    ),\n",
    "    eve_path=None,\n",
    "    components=cfg.data.sdoml.components,\n",
    "    wavelengths=cfg.data.sdoml.wavelengths,\n",
    "    ions=cfg.data.sdoml.ions,\n",
    "    frequency=cfg.data.sdoml.frequency,\n",
    "    batch_size=cfg.model.opt.batch_size,\n",
    "    num_workers=cfg.data.num_workers,\n",
    "    val_months=cfg.data.month_splits.val,\n",
    "    test_months=cfg.data.month_splits.test,\n",
    "    holdout_months=cfg.data.month_splits.holdout,\n",
    "    cache_dir=os.path.join(\n",
    "        cfg.data.sdoml.base_directory, cfg.data.sdoml.sub_directory.cache\n",
    "    ),\n",
    "    min_date=cfg.data.min_date,\n",
    "    max_date=cfg.data.max_date,\n",
    "    num_frames=1,\n",
    ")\n",
    "degraded_data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wandb_version': 1,\n",
       " 'experiment': {'name': 'default',\n",
       "  'project': 'sdofm',\n",
       "  'model': 'samae',\n",
       "  'task': 'pretrain',\n",
       "  'seed': 0,\n",
       "  'disable_cuda': False,\n",
       "  'disable_wandb': False,\n",
       "  'wandb_entity': 'fdlx',\n",
       "  'wandb_group': 'sdofm-phase1',\n",
       "  'wandb_job_type': 'pretrain',\n",
       "  'wandb_tags': [],\n",
       "  'wandb_notes': '',\n",
       "  'fold': None,\n",
       "  'evaluate': False,\n",
       "  'checkpoint': None,\n",
       "  'device': 'cuda',\n",
       "  'precision': 64,\n",
       "  'log_n_batches': 1000,\n",
       "  'save_results': True,\n",
       "  'accelerator': 'auto',\n",
       "  'distributed_enabled': True,\n",
       "  'distributed_backend': 'ddp',\n",
       "  'distributed_world_size': 'auto'},\n",
       " 'data': {'min_date': '0000-00-00 00:00:00',\n",
       "  'max_date': '0000-00-00 00:00:00',\n",
       "  'month_splits_val': [11],\n",
       "  'month_splits_test': [12],\n",
       "  'month_splits_holdout': [],\n",
       "  'num_workers': 16,\n",
       "  'output_directory': 'output',\n",
       "  'sdoml_base_directory': '/mnt/sdoml',\n",
       "  'sdoml_sub_directory_hmi': 'HMI.zarr',\n",
       "  'sdoml_sub_directory_aia': 'AIA.zarr',\n",
       "  'sdoml_sub_directory_eve': 'EVE_legacy.zarr\"',\n",
       "  'sdoml_sub_directory_cache': 'cache',\n",
       "  'sdoml_components': None,\n",
       "  'sdoml_wavelengths': None,\n",
       "  'sdoml_ions': None,\n",
       "  'sdoml_frequency': '12min',\n",
       "  'sdoml_mask_with_hmi_threshold': None},\n",
       " 'model': {'mae': {'img_size': 512,\n",
       "   'patch_size': 16,\n",
       "   'num_frames': 1,\n",
       "   'tubelet_size': 1,\n",
       "   'in_chans': 9,\n",
       "   'embed_dim': 128,\n",
       "   'depth': 24,\n",
       "   'num_heads': 16,\n",
       "   'decoder_embed_dim': 512,\n",
       "   'decoder_depth': 8,\n",
       "   'decoder_num_heads': 16,\n",
       "   'mlp_ratio': 4.0,\n",
       "   'norm_pix_loss': False},\n",
       "  'samae': {'masking_type': 'solar_aware',\n",
       "   'active_region_mu_degs': 15.73,\n",
       "   'active_region_std_degs': 6.14,\n",
       "   'active_region_scale': 1.0,\n",
       "   'active_region_abs_lon_max_degs': 60,\n",
       "   'active_region_abs_lat_max_degs': 60},\n",
       "  'nvae': {'use_se': True,\n",
       "   'res_dist': True,\n",
       "   'num_x_bits': 8,\n",
       "   'num_latent_scales': 3,\n",
       "   'num_groups_per_scale': 1,\n",
       "   'num_latent_per_group': 1,\n",
       "   'ada_groups': True,\n",
       "   'min_groups_per_scale': 1,\n",
       "   'num_channels_enc': 30,\n",
       "   'num_channels_dec': 30,\n",
       "   'num_preprocess_blocks': 2,\n",
       "   'num_preprocess_cells': 2,\n",
       "   'num_cell_per_cond_enc': 2,\n",
       "   'num_postprocess_blocks': 2,\n",
       "   'num_postprocess_cells': 2,\n",
       "   'num_cell_per_cond_dec': 2,\n",
       "   'num_mixture_dec': 1,\n",
       "   'num_nf': 2,\n",
       "   'kl_anneal_portion': 0.3,\n",
       "   'kl_const_portion': 0.0001,\n",
       "   'kl_const_coeff': 0.0001,\n",
       "   'weight_decay_norm_anneal': True,\n",
       "   'weight_decay_norm_init': 1.0,\n",
       "   'weight_decay_norm': 0.01},\n",
       "  'dimming_num_neck_filters': 32,\n",
       "  'dimming_output_dim': 1,\n",
       "  'dimming_loss': 'mse',\n",
       "  'dimming_freeze_encoder': True,\n",
       "  'opt': {'loss': 'mse',\n",
       "   'scheduler': 'constant',\n",
       "   'scheduler_warmup': 0,\n",
       "   'batch_size': 3,\n",
       "   'learning_rate': 0.0001,\n",
       "   'weight_decay': 0.0003,\n",
       "   'optimiser': 'adam',\n",
       "   'epochs': 4,\n",
       "   'patience': 2}},\n",
       " '_wandb': {'code_path': 'code/scripts/main.py',\n",
       "  'python_version': '3.10.14',\n",
       "  'cli_version': '0.16.6',\n",
       "  'framework': 'lightning',\n",
       "  'is_jupyter_run': False,\n",
       "  'is_kaggle_kernel': False,\n",
       "  'start_time': 1713314506.0,\n",
       "  't': {1: [1, 9, 41, 49, 50, 54, 55, 63, 74, 103],\n",
       "   2: [1, 9, 41, 49, 50, 54, 55, 63, 74, 103],\n",
       "   3: [7, 13, 16, 23],\n",
       "   4: '3.10.14',\n",
       "   5: '0.16.6',\n",
       "   8: [5],\n",
       "   13: 'linux-x86_64'},\n",
       "  'm': [{1: 'trainer/global_step', 6: [3]},\n",
       "   {1: 'train_loss', 5: 1, 6: [1]},\n",
       "   {1: 'epoch', 5: 1, 6: [1]},\n",
       "   {1: 'val_loss', 5: 1, 6: [1]}]}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "conf = yaml.safe_load(\n",
    "    Path(\n",
    "        \"/home/walsh/repos/SDO-FM/output/2024-04-17-00-41-29/0/wandb/latest-run/files/config.yaml\"\n",
    "    ).read_text()\n",
    ")\n",
    "backbone_cfg = utils.unflatten_dict(conf, sep=\"___\", wandb_mode=True)\n",
    "backbone_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 'mse',\n",
       " 'scheduler': 'constant',\n",
       " 'scheduler_warmup': 0,\n",
       " 'batch_size': 3,\n",
       " 'learning_rate': 0.0001,\n",
       " 'weight_decay': 0.0003,\n",
       " 'optimiser': 'adam',\n",
       " 'epochs': 4,\n",
       " 'patience': 2}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone_cfg.model.opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = SAMAE.load_from_checkpoint(\n",
    "    **backbone_cfg.model.mae,\n",
    "    **backbone_cfg.model.samae,\n",
    "    optimiser=backbone_cfg.model.opt.optimiser,\n",
    "    lr=backbone_cfg.model.opt.learning_rate,\n",
    "    weight_decay=backbone_cfg.model.opt.weight_decay,\n",
    "    checkpoint_path=\"/home/walsh/repos/SDO-FM/output/2024-04-17-00-41-29/0/sdofm/zy68fa00/checkpoints/epoch=3-step=48556.ckpt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autocalibration(\n",
    "    **cfg.model.mae,\n",
    "    **cfg.model.dimming,\n",
    "    optimiser=cfg.model.opt.optimiser,\n",
    "    lr=cfg.model.opt.learning_rate,\n",
    "    weight_decay=cfg.model.opt.weight_decay,\n",
    "    backbone=backbone\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type                                 | Params\n",
      "-----------------------------------------------------------------------\n",
      "0 | backbone      | SAMAE                                | 32.2 M\n",
      "1 | encoder       | PrithviEncoder                       | 32.2 M\n",
      "2 | decoder       | ConvTransformerTokensToEmbeddingNeck | 28.9 K\n",
      "3 | head          | Autocalibration13                    | 93.4 K\n",
      "4 | loss_function | MSELoss                              | 0     \n",
      "-----------------------------------------------------------------------\n",
      "122 K     Trainable params\n",
      "32.2 M    Non-trainable params\n",
      "32.3 M    Total params\n",
      "129.203   Total estimated model params size (MB)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "dictionary update sequence element #0 has length 1; 2 is required",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/walsh/repos/SDO-FM/notebooks/test_finetuning.ipynb Cell 11\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsdofm-workbench-n1-16cpu-60ram-t4x2.us-central1-a.sdo-fm-2024/home/walsh/repos/SDO-FM/notebooks/test_finetuning.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mTrainer(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsdofm-workbench-n1-16cpu-60ram-t4x2.us-central1-a.sdo-fm-2024/home/walsh/repos/SDO-FM/notebooks/test_finetuning.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     devices\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, accelerator\u001b[39m=\u001b[39mcfg\u001b[39m.\u001b[39mexperiment\u001b[39m.\u001b[39maccelerator, max_epochs\u001b[39m=\u001b[39mcfg\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mopt\u001b[39m.\u001b[39mepochs\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsdofm-workbench-n1-16cpu-60ram-t4x2.us-central1-a.sdo-fm-2024/home/walsh/repos/SDO-FM/notebooks/test_finetuning.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m )\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bsdofm-workbench-n1-16cpu-60ram-t4x2.us-central1-a.sdo-fm-2024/home/walsh/repos/SDO-FM/notebooks/test_finetuning.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(model\u001b[39m=\u001b[39;49mmodel, datamodule\u001b[39m=\u001b[39;49mdegraded_data_module)\n",
      "File \u001b[0;32m/opt/conda/envs/sdofm/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:544\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m TrainerStatus\u001b[39m.\u001b[39mRUNNING\n\u001b[1;32m    543\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    545\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    546\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/envs/sdofm/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     46\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m/opt/conda/envs/sdofm/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:580\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    574\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    575\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[1;32m    576\u001b[0m     ckpt_path,\n\u001b[1;32m    577\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    578\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    579\u001b[0m )\n\u001b[0;32m--> 580\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[1;32m    582\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    583\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/sdofm/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:970\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    967\u001b[0m     call\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mon_fit_start\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    968\u001b[0m     call\u001b[39m.\u001b[39m_call_lightning_module_hook(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mon_fit_start\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 970\u001b[0m _log_hyperparams(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    972\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mrestore_checkpoint_after_setup:\n\u001b[1;32m    973\u001b[0m     log\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: restoring module and callbacks from checkpoint path: \u001b[39m\u001b[39m{\u001b[39;00mckpt_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/sdofm/lib/python3.10/site-packages/lightning/pytorch/loggers/utilities.py:95\u001b[0m, in \u001b[0;36m_log_hyperparams\u001b[0;34m(trainer)\u001b[0m\n\u001b[1;32m     93\u001b[0m     logger\u001b[39m.\u001b[39mlog_hyperparams(hparams_initial)\n\u001b[1;32m     94\u001b[0m logger\u001b[39m.\u001b[39mlog_graph(pl_module)\n\u001b[0;32m---> 95\u001b[0m logger\u001b[39m.\u001b[39;49msave()\n",
      "File \u001b[0;32m/opt/conda/envs/sdofm/lib/python3.10/site-packages/lightning_utilities/core/rank_zero.py:42\u001b[0m, in \u001b[0;36mrank_zero_only.<locals>.wrapped_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mThe `rank_zero_only.rank` needs to be set before use\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[39mif\u001b[39;00m rank \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 42\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     43\u001b[0m \u001b[39mreturn\u001b[39;00m default\n",
      "File \u001b[0;32m/opt/conda/envs/sdofm/lib/python3.10/site-packages/lightning/pytorch/loggers/tensorboard.py:221\u001b[0m, in \u001b[0;36mTensorBoardLogger.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[39m# save the metatags file if it doesn't exist and the log directory exists\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[39mif\u001b[39;00m _is_dir(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fs, dir_path) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fs\u001b[39m.\u001b[39misfile(hparams_file):\n\u001b[0;32m--> 221\u001b[0m     save_hparams_to_yaml(hparams_file, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhparams)\n",
      "File \u001b[0;32m/opt/conda/envs/sdofm/lib/python3.10/site-packages/lightning/pytorch/core/saving.py:354\u001b[0m, in \u001b[0;36msave_hparams_to_yaml\u001b[0;34m(config_yaml, hparams, use_omegaconf)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    353\u001b[0m     v \u001b[39m=\u001b[39m v\u001b[39m.\u001b[39mname \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(v, Enum) \u001b[39melse\u001b[39;00m v\n\u001b[0;32m--> 354\u001b[0m     yaml\u001b[39m.\u001b[39;49mdump(v)\n\u001b[1;32m    355\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    356\u001b[0m     warn(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSkipping \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mk\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m parameter because it is not possible to safely dump to YAML.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/sdofm/lib/python3.10/site-packages/yaml/__init__.py:253\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(data, stream, Dumper, **kwds)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(data, stream\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, Dumper\u001b[39m=\u001b[39mDumper, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds):\n\u001b[1;32m    249\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m    Serialize a Python object into a YAML stream.\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \u001b[39m    If stream is None, return the produced string instead.\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 253\u001b[0m     \u001b[39mreturn\u001b[39;00m dump_all([data], stream, Dumper\u001b[39m=\u001b[39;49mDumper, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m/opt/conda/envs/sdofm/lib/python3.10/site-packages/yaml/__init__.py:241\u001b[0m, in \u001b[0;36mdump_all\u001b[0;34m(documents, stream, Dumper, default_style, default_flow_style, canonical, indent, width, allow_unicode, line_break, encoding, explicit_start, explicit_end, version, tags, sort_keys)\u001b[0m\n\u001b[1;32m    239\u001b[0m     dumper\u001b[39m.\u001b[39mopen()\n\u001b[1;32m    240\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m documents:\n\u001b[0;32m--> 241\u001b[0m         dumper\u001b[39m.\u001b[39;49mrepresent(data)\n\u001b[1;32m    242\u001b[0m     dumper\u001b[39m.\u001b[39mclose()\n\u001b[1;32m    243\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/sdofm/lib/python3.10/site-packages/yaml/representer.py:27\u001b[0m, in \u001b[0;36mBaseRepresenter.represent\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrepresent\u001b[39m(\u001b[39mself\u001b[39m, data):\n\u001b[0;32m---> 27\u001b[0m     node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrepresent_data(data)\n\u001b[1;32m     28\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mserialize(node)\n\u001b[1;32m     29\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrepresented_objects \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m/opt/conda/envs/sdofm/lib/python3.10/site-packages/yaml/representer.py:52\u001b[0m, in \u001b[0;36mBaseRepresenter.represent_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mfor\u001b[39;00m data_type \u001b[39min\u001b[39;00m data_types:\n\u001b[1;32m     51\u001b[0m     \u001b[39mif\u001b[39;00m data_type \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39myaml_multi_representers:\n\u001b[0;32m---> 52\u001b[0m         node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49myaml_multi_representers[data_type](\u001b[39mself\u001b[39;49m, data)\n\u001b[1;32m     53\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/sdofm/lib/python3.10/site-packages/yaml/representer.py:342\u001b[0m, in \u001b[0;36mRepresenter.represent_object\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    339\u001b[0m function_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (function\u001b[39m.\u001b[39m\u001b[39m__module__\u001b[39m, function\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    340\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m args \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m listitems \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m dictitems \\\n\u001b[1;32m    341\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(state, \u001b[39mdict\u001b[39m) \u001b[39mand\u001b[39;00m newobj:\n\u001b[0;32m--> 342\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrepresent_mapping(\n\u001b[1;32m    343\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mtag:yaml.org,2002:python/object:\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m+\u001b[39;49mfunction_name, state)\n\u001b[1;32m    344\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m listitems \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m dictitems  \\\n\u001b[1;32m    345\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(state, \u001b[39mdict\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m state:\n\u001b[1;32m    346\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrepresent_sequence(tag\u001b[39m+\u001b[39mfunction_name, args)\n",
      "File \u001b[0;32m/opt/conda/envs/sdofm/lib/python3.10/site-packages/yaml/representer.py:118\u001b[0m, in \u001b[0;36mBaseRepresenter.represent_mapping\u001b[0;34m(self, tag, mapping, flow_style)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[39mfor\u001b[39;00m item_key, item_value \u001b[39min\u001b[39;00m mapping:\n\u001b[1;32m    117\u001b[0m     node_key \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrepresent_data(item_key)\n\u001b[0;32m--> 118\u001b[0m     node_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrepresent_data(item_value)\n\u001b[1;32m    119\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39misinstance\u001b[39m(node_key, ScalarNode) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m node_key\u001b[39m.\u001b[39mstyle):\n\u001b[1;32m    120\u001b[0m         best_style \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/sdofm/lib/python3.10/site-packages/yaml/representer.py:52\u001b[0m, in \u001b[0;36mBaseRepresenter.represent_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mfor\u001b[39;00m data_type \u001b[39min\u001b[39;00m data_types:\n\u001b[1;32m     51\u001b[0m     \u001b[39mif\u001b[39;00m data_type \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39myaml_multi_representers:\n\u001b[0;32m---> 52\u001b[0m         node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49myaml_multi_representers[data_type](\u001b[39mself\u001b[39;49m, data)\n\u001b[1;32m     53\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/sdofm/lib/python3.10/site-packages/yaml/representer.py:330\u001b[0m, in \u001b[0;36mRepresenter.represent_object\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    328\u001b[0m     listitems \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(listitems)\n\u001b[1;32m    329\u001b[0m \u001b[39mif\u001b[39;00m dictitems \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 330\u001b[0m     dictitems \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39;49m(dictitems)\n\u001b[1;32m    331\u001b[0m \u001b[39mif\u001b[39;00m function\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__newobj__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    332\u001b[0m     function \u001b[39m=\u001b[39m args[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: dictionary update sequence element #0 has length 1; 2 is required"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    devices=1, accelerator=cfg.experiment.accelerator, max_epochs=cfg.model.opt.epochs\n",
    ")\n",
    "trainer.fit(model=model, datamodule=degraded_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdofm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
