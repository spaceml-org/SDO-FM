{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import wandb\n",
    "from sdofm import utils\n",
    "from sdofm.datasets import SDOMLDataModule\n",
    "from sdofm.pretraining import MAE\n",
    "from scripts.pretrain import Pretrainer\n",
    "from lightning.pytorch.loggers.wandb import WandbLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import omegaconf\n",
    "\n",
    "cfg = omegaconf.OmegaConf.load(\"../experiments/finetune_32.2M_mae_virtualeve.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[* CACHE SYSTEM *] Found cached index data in /mnt/sdoml/cache/aligndata_AIA_FULL_12min.csv.\n",
      "[* CACHE SYSTEM *] Found cached normalization data in /mnt/sdoml/cache/normalizations_AIA_FULL_12min.json.\n",
      "[* CACHE SYSTEM *] Found cached HMI mask data in /mnt/sdoml/cache/hmi_mask_512x512.npy.\n"
     ]
    }
   ],
   "source": [
    "data_module = SDOMLDataModule(\n",
    "    hmi_path=None,\n",
    "    aia_path=os.path.join(\n",
    "        cfg.data.sdoml.base_directory, cfg.data.sdoml.sub_directory.aia\n",
    "    ),\n",
    "    eve_path=None,\n",
    "    components=cfg.data.sdoml.components,\n",
    "    wavelengths=cfg.data.sdoml.wavelengths,\n",
    "    ions=cfg.data.sdoml.ions,\n",
    "    frequency=cfg.data.sdoml.frequency,\n",
    "    batch_size=cfg.model.opt.batch_size,\n",
    "    num_workers=cfg.data.num_workers,\n",
    "    val_months=cfg.data.month_splits.val,\n",
    "    test_months=cfg.data.month_splits.test,\n",
    "    holdout_months=cfg.data.month_splits.holdout,\n",
    "    cache_dir=os.path.join(\n",
    "        cfg.data.sdoml.base_directory, cfg.data.sdoml.sub_directory.cache\n",
    "    ),\n",
    ")\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[* CACHE SYSTEM *] Found cached index data in /mnt/sdoml/cache/aligndata_AIA_FULL_12min.csv.\n",
      "[* CACHE SYSTEM *] Found cached normalization data in /mnt/sdoml/cache/normalizations_AIA_FULL_12min.json.\n",
      "[* CACHE SYSTEM *] Found cached HMI mask data in /mnt/sdoml/cache/hmi_mask_512x512.npy.\n",
      "Loading checkpoint...\n",
      "Found pre-downloaded checkpoint at artifacts/model-tk45el88:v12/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/sdofm/lib/python3.10/site-packages/lightning/pytorch/utilities/migration/utils.py:56: The loaded checkpoint was produced with Lightning v2.2.5, which is newer than your current Lightning version: v2.2.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded from artifacts/model-tk45el88:v12/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "#model = MAE(\n",
    "#    **cfg.model.mae,\n",
    "    #    **cfg.model.samae,\n",
    "    #    hmi_mask=data_module.hmi_mask,\n",
    "#    optimiser=cfg.model.opt.optimiser,\n",
    "#    lr=cfg.model.opt.learning_rate,\n",
    "#    weight_decay=cfg.model.opt.weight_decay,\n",
    "    \n",
    "#)\n",
    "\n",
    "logger = WandbLogger(\n",
    "    # WandbLogger params\n",
    "    name=cfg.experiment.name,\n",
    "    project=cfg.experiment.project,\n",
    "    dir=cfg.experiment.wandb.output_directory,\n",
    "    log_model=cfg.experiment.wandb.log_model,\n",
    "    # kwargs for wandb.init\n",
    "    tags=cfg.experiment.wandb.tags,\n",
    "    notes=cfg.experiment.wandb.notes,\n",
    "    group=cfg.experiment.wandb.group,\n",
    "    save_code=True,\n",
    "    job_type=cfg.experiment.wandb.job_type,\n",
    "\n",
    ")\n",
    "model = Pretrainer(cfg, logger=logger, is_backbone=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = data_module.valid_ds\n",
    "train_dataset = data_module.train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.to(\"cuda\");\n",
    "model.model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43131, 450432)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset.__len__(), train_dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dates = []\n",
    "for i in range(train_dataset.__len__()):\n",
    "\n",
    "    dates.append(train_dataset.aligndata.iloc[i].name)\n",
    "\n",
    "dates_df = pd.DataFrame(dates, columns=[\"date\"])\n",
    "\n",
    "dates_df.reset_index(inplace=True, drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_df['year'] = pd.to_datetime(dates_df['date']).dt.year\n",
    "dates_df['month'] = pd.to_datetime(dates_df['date']).dt.month\n",
    "dates_df['day'] = pd.to_datetime(dates_df['date']).dt.day\n",
    "dates_df['hour'] = pd.to_datetime(dates_df['date']).dt.hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_6131/3167740649.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_2011_subset = df_2011.groupby('month').apply(lambda x: x.sample(100, random_state=1)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "df_2011 = dates_df[dates_df['year'] == 2011]\n",
    "# groupby month, select 100 random samples\n",
    "df_2011_subset = df_2011.groupby('month').apply(lambda x: x.sample(100, random_state=1)).reset_index(drop=True)\n",
    "quiet_months = [1, 2, 5, 6, 7, 8]\n",
    "df_2011_subset['is_active'] = df_2011_subset['month'].apply(lambda x: 0 if x in quiet_months else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 493/1000 [10:17<12:46,  1.51s/it]"
     ]
    }
   ],
   "source": [
    "cls_embeddings = []\n",
    "mean_embeddings = []\n",
    "names = []\n",
    "\n",
    "for idx in tqdm(df_2011_subset['index'].values):\n",
    "    batch = train_dataset[idx]\n",
    "    name = train_dataset.aligndata.iloc[idx].name\n",
    "    batch = torch.tensor(batch).unsqueeze(0)    \n",
    "    batch = batch.to(\"cuda\")    \n",
    "    x, mask, ids_restore = model.model.forward_encoder(batch, mask_ratio = 0)\n",
    "    # cls_token \n",
    "    cls_embedding = x[:,0,:].detach().cpu()\n",
    "    mean_embedding = x[:,1:,:].mean(dim=1).detach().cpu()\n",
    "    cls_embeddings.append(cls_embedding)\n",
    "    mean_embeddings.append(mean_embedding)\n",
    "    names.append(name)\n",
    "cls_embeddings = torch.cat(cls_embeddings, dim=0)\n",
    "mean_embeddings = torch.cat(mean_embeddings, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num_samples = 5000\n",
    "cls_embeddings = []\n",
    "mean_embeddings = []\n",
    "names = []\n",
    "for i in tqdm(range(num_samples)):\n",
    "    batch = val_dataset[i]\n",
    "    name = val_dataset.aligndata.iloc[i].name\n",
    "    batch = torch.tensor(batch).unsqueeze(0)    \n",
    "    batch = batch.to(\"cuda\")    \n",
    "    x, mask, ids_restore = model.model.forward_encoder(batch, mask_ratio = 0)\n",
    "    # cls_token \n",
    "    cls_embedding = x[:,0,:].detach().cpu()\n",
    "    mean_embedding = x[:,1:,:].mean(dim=1).detach().cpu()\n",
    "    cls_embeddings.append(cls_embedding)\n",
    "    mean_embeddings.append(mean_embedding)\n",
    "    names.append(name)\n",
    "cls_embeddings = torch.cat(cls_embeddings, dim=0)\n",
    "mean_embeddings = torch.cat(mean_embeddings, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "\n",
    "cls_embeddings_np = cls_embeddings.numpy()\n",
    "cls_embeddings_tsne = tsne.fit_transform(cls_embeddings_np)\n",
    "\n",
    "\n",
    "\n",
    "df_2011_subset['cls_tsne_x'] = cls_embeddings_tsne[:,0]\n",
    "df_2011_subset['cls_tsne_y'] = cls_embeddings_tsne[:,1]\n",
    "\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "\n",
    "mean_embeddings_np = mean_embeddings.numpy()\n",
    "mean_embeddings_tsne = tsne.fit_transform(mean_embeddings_np)\n",
    "\n",
    "\n",
    "\n",
    "df_2011_subset['avg_tsne_x'] = mean_embeddings_tsne[:,0]\n",
    "df_2011_subset['avg_tsne_y'] = mean_embeddings_tsne[:,1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = px.scatter(df_2011_subset, x=\"cls_tsne_x\", y=\"cls_tsne_y\", color=\"is_active\", hover_data=[\"month\", \"day\", \"hour\"])\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(df_2011_subset, x=\"avg_tsne_x\", y=\"avg_tsne_y\", color=\"is_active\", hover_data=[\"month\", \"day\", \"hour\"])\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save html\n",
    "fig.write_html(\"mean_pooling_tsne.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdofm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
