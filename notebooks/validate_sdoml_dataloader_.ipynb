{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zarr\n",
    "import dask.array as da\n",
    "import dask\n",
    "from dask.diagnostics import ProgressBar\n",
    "from dask.array import stats\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pytorch_lightning as pl\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdofm.datasets.ZarrIrradianceDataModuleHMI import ZarrIrradianceDataModuleHMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data alignment calculation begin:\n",
      "--------------------------------------------------\n",
      "Aligning AIA data\n",
      "Aligning AIA data for wavelength: 131A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:24<00:00,  4.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning AIA data for wavelength: 1600A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:23<00:00,  4.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning AIA data for wavelength: 1700A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:20<00:00,  4.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning AIA data for wavelength: 171A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:22<00:00,  4.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning AIA data for wavelength: 193A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:20<00:00,  4.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning AIA data for wavelength: 211A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:21<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning AIA data for wavelength: 304A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:20<00:00,  4.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning AIA data for wavelength: 335A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:21<00:00,  4.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning AIA data for wavelength: 94A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:20<00:00,  4.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIA alignment completed with 177481 samples.\n",
      "Aligning HMI data\n",
      "Aligning HMI data for component: Bx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:16<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HMI alignment completed with 164426 samples.\n",
      "Aligning EVE data\n",
      "\n",
      "##################################################\n",
      "[*] Total Alignment Completed with 16 Samples.\n",
      "##################################################\n",
      "\n",
      "\n",
      "Calculating normalizations for wavelength 131A:\n",
      "--------------------------------------------------\n",
      "Sum:\n",
      "[########################################] | 100% Completed | 2.32 ss\n",
      "Max Pixel Value:\n",
      "[########################################] | 100% Completed | 202.89 ms\n",
      "Standard Deviation:\n",
      "[########################################] | 100% Completed | 203.06 ms\n",
      "Skew:\n",
      "[########################################] | 100% Completed | 404.22 ms\n",
      "Kurtosis:\n",
      "[########################################] | 100% Completed | 404.27 ms\n",
      "\n",
      "Calculating normalizations for wavelength 1600A:\n",
      "--------------------------------------------------\n",
      "Sum:\n",
      "[########################################] | 100% Completed | 1.92 ss\n",
      "Max Pixel Value:\n",
      "[########################################] | 100% Completed | 304.39 ms\n",
      "Standard Deviation:\n",
      "[########################################] | 100% Completed | 304.68 ms\n",
      "Skew:\n",
      "[########################################] | 100% Completed | 404.79 ms\n",
      "Kurtosis:\n",
      "[########################################] | 100% Completed | 404.63 ms\n",
      "\n",
      "Calculating normalizations for wavelength 1700A:\n",
      "--------------------------------------------------\n",
      "Sum:\n",
      "[########################################] | 100% Completed | 1.92 ss\n",
      "Max Pixel Value:\n",
      "[########################################] | 100% Completed | 202.72 ms\n",
      "Standard Deviation:\n",
      "[########################################] | 100% Completed | 304.25 ms\n",
      "Skew:\n",
      "[########################################] | 100% Completed | 404.55 ms\n",
      "Kurtosis:\n",
      "[########################################] | 100% Completed | 505.54 ms\n",
      "\n",
      "Calculating normalizations for wavelength 171A:\n",
      "--------------------------------------------------\n",
      "Sum:\n",
      "[########################################] | 100% Completed | 1.31 ss\n",
      "Max Pixel Value:\n",
      "[########################################] | 100% Completed | 304.13 ms\n",
      "Standard Deviation:\n",
      "[########################################] | 100% Completed | 303.65 ms\n",
      "Skew:\n",
      "[########################################] | 100% Completed | 404.95 ms\n",
      "Kurtosis:\n",
      "[########################################] | 100% Completed | 506.74 ms\n",
      "\n",
      "Calculating normalizations for wavelength 193A:\n",
      "--------------------------------------------------\n",
      "Sum:\n",
      "[########################################] | 100% Completed | 1.41 ss\n",
      "Max Pixel Value:\n",
      "[########################################] | 100% Completed | 304.14 ms\n",
      "Standard Deviation:\n",
      "[########################################] | 100% Completed | 303.81 ms\n",
      "Skew:\n",
      "[########################################] | 100% Completed | 405.26 ms\n",
      "Kurtosis:\n",
      "[########################################] | 100% Completed | 505.76 ms\n",
      "\n",
      "Calculating normalizations for wavelength 211A:\n",
      "--------------------------------------------------\n",
      "Sum:\n",
      "[########################################] | 100% Completed | 1.51 ss\n",
      "Max Pixel Value:\n",
      "[########################################] | 100% Completed | 303.81 ms\n",
      "Standard Deviation:\n",
      "[########################################] | 100% Completed | 303.83 ms\n",
      "Skew:\n",
      "[########################################] | 100% Completed | 404.97 ms\n",
      "Kurtosis:\n",
      "[########################################] | 100% Completed | 505.61 ms\n",
      "\n",
      "Calculating normalizations for wavelength 304A:\n",
      "--------------------------------------------------\n",
      "Sum:\n",
      "[########################################] | 100% Completed | 1.31 ss\n",
      "Max Pixel Value:\n",
      "[########################################] | 100% Completed | 202.27 ms\n",
      "Standard Deviation:\n",
      "[########################################] | 100% Completed | 202.73 ms\n",
      "Skew:\n",
      "[########################################] | 100% Completed | 405.96 ms\n",
      "Kurtosis:\n",
      "[########################################] | 100% Completed | 505.77 ms\n",
      "\n",
      "Calculating normalizations for wavelength 335A:\n",
      "--------------------------------------------------\n",
      "Sum:\n",
      "[########################################] | 100% Completed | 1.51 ss\n",
      "Max Pixel Value:\n",
      "[########################################] | 100% Completed | 202.69 ms\n",
      "Standard Deviation:\n",
      "[########################################] | 100% Completed | 303.84 ms\n",
      "Skew:\n",
      "[########################################] | 100% Completed | 304.21 ms\n",
      "Kurtosis:\n",
      "[########################################] | 100% Completed | 506.20 ms\n",
      "\n",
      "Calculating normalizations for wavelength 94A:\n",
      "--------------------------------------------------\n",
      "Sum:\n",
      "[########################################] | 100% Completed | 1.31 ss\n",
      "Max Pixel Value:\n",
      "[########################################] | 100% Completed | 202.80 ms\n",
      "Standard Deviation:\n",
      "[########################################] | 100% Completed | 304.91 ms\n",
      "Skew:\n",
      "[########################################] | 100% Completed | 404.71 ms\n",
      "Kurtosis:\n",
      "[########################################] | 100% Completed | 507.13 ms\n",
      "\n",
      "Calculating normalizations for component Bx:\n",
      "--------------------------------------------------\n",
      "Sum:\n",
      "[########################################] | 100% Completed | 202.51 ms\n",
      "Max Pixel Value:\n",
      "[########################################] | 100% Completed | 202.51 ms\n",
      "Standard Deviation:\n",
      "[########################################] | 100% Completed | 202.35 ms\n",
      "Skew:\n",
      "[########################################] | 100% Completed | 304.60 ms\n",
      "Kurtosis:\n",
      "[########################################] | 100% Completed | 404.73 ms\n",
      "\n",
      "Calculating normalizations for component By:\n",
      "--------------------------------------------------\n",
      "Sum:\n",
      "[########################################] | 100% Completed | 1.21 ss\n",
      "Max Pixel Value:\n",
      "[########################################] | 100% Completed | 203.31 ms\n",
      "Standard Deviation:\n",
      "[########################################] | 100% Completed | 202.76 ms\n",
      "Skew:\n",
      "[########################################] | 100% Completed | 303.75 ms\n",
      "Kurtosis:\n",
      "[########################################] | 100% Completed | 405.32 ms\n",
      "\n",
      "Calculating normalizations for component Bz:\n",
      "--------------------------------------------------\n",
      "Sum:\n",
      "[########################################] | 100% Completed | 1.11 ss\n",
      "Max Pixel Value:\n",
      "[########################################] | 100% Completed | 202.69 ms\n",
      "Standard Deviation:\n",
      "[########################################] | 100% Completed | 202.42 ms\n",
      "Skew:\n",
      "[########################################] | 100% Completed | 304.02 ms\n",
      "Kurtosis:\n",
      "[########################################] | 100% Completed | 404.94 ms\n"
     ]
    }
   ],
   "source": [
    "hmi_path = \"/mnt/sdoml/HMI.zarr\"\n",
    "aia_path = \"/mnt/sdoml/AIA.zarr\"\n",
    "eve_path = \"/mnt/sdoml/EVE_legacy.zarr\"\n",
    "components = [\"Bx\", \"By\", \"Bz\"]\n",
    "wavelengths = [\"131A\",\"1600A\",\"1700A\",\"171A\",\"193A\",\"211A\",\"304A\",\"335A\",\"94A\"]\n",
    "ions = [\"C III\", \"Fe IX\", \"Fe VIII\", \"Fe X\", \"Fe XI\", \"Fe XII\", \"Fe XIII\", \"Fe XIV\", \"Fe XIX\", \"Fe XV\", \"Fe XVI\", \"Fe XVIII\", \"Fe XVI_2\", \"Fe XX\", \"Fe XX_2\", \"Fe XX_3\", \"H I\", \"H I_2\", \"H I_3\", \"He I\", \"He II\", \"He II_2\", \"He I_2\", \"Mg IX\", \"Mg X\", \"Mg X_2\", \"Ne VII\", \"Ne VIII\", \"O II\", \"O III\", \"O III_2\", \"O II_2\", \"O IV\", \"O IV_2\", \"O V\", \"O VI\", \"S XIV\", \"Si XII\", \"Si XII_2\"]\n",
    "frequency = \"12min\"\n",
    "batch_size = 32\n",
    "\n",
    "test = ZarrIrradianceDataModuleHMI(hmi_path, aia_path, eve_path, components, wavelengths, ions, frequency, batch_size, num_workers=16, val_months=[10,1], test_months=[11,12],  holdout_months=[], cache_dir=\"/home/walsh/repos/SDO-FM/notebooks/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmi_data = zarr.group(zarr.DirectoryStore(\"/mnt/sdoml/EVE_legacy.zarr/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abed63d69bd54df7bc8c660a21db950d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tree(nodes=(Node(disabled=True, name='/', nodes=(Node(disabled=True, icon='table', name='C III (2137380,) floa…"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmi_data.tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [\"C III\", \"Fe IX\", \"Fe VIII\", \"Fe X\", \"Fe XI\", \"Fe XII\", \"Fe XIII\", \"Fe XIV\", \"Fe XIX\", \"Fe XV\", \"Fe XVI\", \"Fe XVIII\", \"Fe XVI_2\", \"Fe XX\", \"Fe XX_2\", \"Fe XX_3\", \"H I\", \"H I_2\", \"H I_3\", \"He I\", \"He II\", \"He II_2\", \"He I_2\", \"Mg IX\", \"Mg X\", \"Mg X_2\", \"Ne VII\", \"Ne VIII\", \"O II\", \"O III\", \"O III_2\", \"O II_2\", \"O IV\", \"O IV_2\", \"O V\", \"O VI\", \"S XIV\", \"Si XII\", \"Si XII_2\"]\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data alignment calculation begin:\n",
      "--------------------------------------------------\n",
      "Aligning AIA data\n",
      "Aligning AIA data for wavelength: 131A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:10<00:00,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning AIA data for wavelength: 1600A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:09<00:00,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning AIA data for wavelength: 1700A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:09<00:00,  1.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning AIA data for wavelength: 171A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:09<00:00,  1.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning AIA data for wavelength: 193A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:09<00:00,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning AIA data for wavelength: 211A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:09<00:00,  1.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning AIA data for wavelength: 304A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:09<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning AIA data for wavelength: 335A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:03<00:12,  3.15s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/walsh/repos/SDO-FM/notebooks/validate_sdoml_dataloader_.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsdofm-workbench-n1-16cpu-60ram-t4x2.us-central1-a.sdo-fm-2024/home/walsh/repos/SDO-FM/notebooks/validate_sdoml_dataloader_.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m frequency \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m6min\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsdofm-workbench-n1-16cpu-60ram-t4x2.us-central1-a.sdo-fm-2024/home/walsh/repos/SDO-FM/notebooks/validate_sdoml_dataloader_.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m32\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bsdofm-workbench-n1-16cpu-60ram-t4x2.us-central1-a.sdo-fm-2024/home/walsh/repos/SDO-FM/notebooks/validate_sdoml_dataloader_.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m test \u001b[39m=\u001b[39m ZarrIrradianceDataModuleHMI(hmi_path, aia_path, eve_path, components, wavelengths, ions, frequency, batch_size, num_workers\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m, val_months\u001b[39m=\u001b[39;49m[\u001b[39m10\u001b[39;49m,\u001b[39m1\u001b[39;49m], test_months\u001b[39m=\u001b[39;49m[\u001b[39m11\u001b[39;49m,\u001b[39m12\u001b[39;49m],  holdout_months\u001b[39m=\u001b[39;49m[], cache_dir\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m/home/walsh/repos/SDO-FM/notebooks/\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m/home/walsh/repos/SDO-FM/sdofm/datasets/ZarrIrradianceDataModuleHMI.py:285\u001b[0m, in \u001b[0;36mZarrIrradianceDataModuleHMI.__init__\u001b[0;34m(self, hmi_path, aia_path, eve_path, components, wavelengths, ions, frequency, batch_size, num_workers, val_months, test_months, holdout_months, cache_dir)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnormalizations_cache_filename \u001b[39m=\u001b[39m (\n\u001b[1;32m    281\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mcache_dir\u001b[39m}\u001b[39;00m\u001b[39m/normalizations_\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache_id\u001b[39m}\u001b[39;00m\u001b[39m.json\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m )\n\u001b[1;32m    284\u001b[0m \u001b[39m# Temporal alignment of hmi, aia and eve data\u001b[39;00m\n\u001b[0;32m--> 285\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maligndata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__aligntime()\n\u001b[1;32m    286\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnormalizations \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__calc_normalizations()\n",
      "File \u001b[0;32m/home/walsh/repos/SDO-FM/sdofm/datasets/ZarrIrradianceDataModuleHMI.py:324\u001b[0m, in \u001b[0;36mZarrIrradianceDataModuleHMI.__aligntime\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    321\u001b[0m aia_channel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maia_data[year][wavelength]\n\u001b[1;32m    323\u001b[0m \u001b[39m# get observation time\u001b[39;00m\n\u001b[0;32m--> 324\u001b[0m t_obs_aia_channel \u001b[39m=\u001b[39m aia_channel\u001b[39m.\u001b[39;49mattrs[\u001b[39m\"\u001b[39;49m\u001b[39mT_OBS\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m j \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    326\u001b[0m     \u001b[39m# transform to DataFrame\u001b[39;00m\n\u001b[1;32m    327\u001b[0m     \u001b[39m# AIA\u001b[39;00m\n\u001b[1;32m    328\u001b[0m     df_t_aia \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(\n\u001b[1;32m    329\u001b[0m         {\n\u001b[1;32m    330\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mTime\u001b[39m\u001b[39m\"\u001b[39m: pd\u001b[39m.\u001b[39mto_datetime(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    336\u001b[0m         }\n\u001b[1;32m    337\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/zarr/attrs.py:74\u001b[0m, in \u001b[0;36mAttributes.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, item):\n\u001b[0;32m---> 74\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49masdict()[item]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/zarr/attrs.py:55\u001b[0m, in \u001b[0;36mAttributes.asdict\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_asdict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_asdict\n\u001b[0;32m---> 55\u001b[0m d \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_nosync()\n\u001b[1;32m     56\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_version \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m     57\u001b[0m     d \u001b[39m=\u001b[39m d[\u001b[39m\"\u001b[39m\u001b[39mattributes\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/zarr/attrs.py:48\u001b[0m, in \u001b[0;36mAttributes._get_nosync\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     46\u001b[0m         d[\u001b[39m\"\u001b[39m\u001b[39mattributes\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m {}\n\u001b[1;32m     47\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 48\u001b[0m     d \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstore\u001b[39m.\u001b[39;49m_metadata_class\u001b[39m.\u001b[39;49mparse_metadata(data)\n\u001b[1;32m     49\u001b[0m \u001b[39mreturn\u001b[39;00m d\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/zarr/meta.py:103\u001b[0m, in \u001b[0;36mMetadata2.parse_metadata\u001b[0;34m(cls, s)\u001b[0m\n\u001b[1;32m     99\u001b[0m     meta \u001b[39m=\u001b[39m s\n\u001b[1;32m    101\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m     \u001b[39m# assume metadata needs to be parsed as JSON\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m     meta \u001b[39m=\u001b[39m json_loads(s)\n\u001b[1;32m    105\u001b[0m \u001b[39mreturn\u001b[39;00m meta\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/zarr/util.py:76\u001b[0m, in \u001b[0;36mjson_loads\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mjson_loads\u001b[39m(s: Union[\u001b[39mbytes\u001b[39m, \u001b[39mstr\u001b[39m]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, Any]:\n\u001b[1;32m     75\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Read JSON in a consistent way.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m     \u001b[39mreturn\u001b[39;00m json\u001b[39m.\u001b[39;49mloads(ensure_text(s, \u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "File \u001b[0;32m/opt/conda/envs/sdofm/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[39m=\u001b[39m s\u001b[39m.\u001b[39mdecode(detect_encoding(s), \u001b[39m'\u001b[39m\u001b[39msurrogatepass\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_decoder\u001b[39m.\u001b[39;49mdecode(s)\n\u001b[1;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/opt/conda/envs/sdofm/lib/python3.10/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, s, _w\u001b[39m=\u001b[39mWHITESPACE\u001b[39m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[39m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_decode(s, idx\u001b[39m=\u001b[39;49m_w(s, \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mend())\n\u001b[1;32m    338\u001b[0m     end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[39mif\u001b[39;00m end \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(s):\n",
      "File \u001b[0;32m/opt/conda/envs/sdofm/lib/python3.10/json/decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[39ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[39mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    350\u001b[0m \n\u001b[1;32m    351\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 353\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    355\u001b[0m     \u001b[39mraise\u001b[39;00m JSONDecodeError(\u001b[39m\"\u001b[39m\u001b[39mExpecting value\u001b[39m\u001b[39m\"\u001b[39m, s, err\u001b[39m.\u001b[39mvalue) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hmi_path = \"/mnt/sdoml/HMI.zarr\"\n",
    "aia_path = \"/mnt/sdoml/AIA.zarr\"\n",
    "eve_path = \"/mnt/sdoml/EVE_legacy.zarr\"\n",
    "components = [\"Bx\", \"By\", \"Bz\"]\n",
    "wavelengths = [\"131A\",\"1600A\",\"1700A\",\"171A\",\"193A\",\"211A\",\"304A\",\"335A\",\"94A\"]\n",
    "ions = [\"C III\", \"Fe IX\", \"Fe VIII\", \"Fe X\", \"Fe XI\", \"Fe XII\", \"Fe XIII\", \"Fe XIV\", \"Fe XIX\", \"Fe XV\", \"Fe XVI\", \"Fe XVIII\", \"Fe XVI_2\", \"Fe XX\", \"Fe XX_2\", \"Fe XX_3\", \"H I\", \"H I_2\", \"H I_3\", \"He I\", \"He II\", \"He II_2\", \"He I_2\", \"Mg IX\", \"Mg X\", \"Mg X_2\", \"Ne VII\", \"Ne VIII\", \"O II\", \"O III\", \"O III_2\", \"O II_2\", \"O IV\", \"O IV_2\", \"O V\", \"O VI\", \"S XIV\", \"Si XII\", \"Si XII_2\"]\n",
    "frequency = \"6min\"\n",
    "batch_size = 32\n",
    "\n",
    "test = ZarrIrradianceDataModuleHMI(hmi_path, aia_path, eve_path, components, wavelengths, ions, frequency, batch_size, num_workers=16, val_months=[10,1], test_months=[11,12],  holdout_months=[], cache_dir=\"/home/walsh/repos/SDO-FM/notebooks/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.valid_ds.__getitem__(0)[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Older versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZarrIrradianceDataModuleHMI(pl.LightningDataModule):\n",
    "    \"\"\" Loads paired data samples of AIA EUV images and EVE irradiance measures.\n",
    "\n",
    "    Note: Input data needs to be paired.\n",
    "    Parameters\n",
    "    ----------\n",
    "    aia_path: path to aia zarr file\n",
    "    eve_path: path to the EVE zarr data file\n",
    "    batch_size: batch size (default is 32)\n",
    "    num_workers: number of workers (needed for the training)\n",
    "    val_months: \n",
    "    \"\"\"\n",
    "    def __init__(self, hmi_path, aia_path, eve_path, components, wavelengths, ions, frequency, batch_size: int = 32, num_workers=None, val_months=[10,1], test_months=[11,12],  holdout_months=[], cache_dir=\"\"):\n",
    "\n",
    "        super().__init__()\n",
    "        self.num_workers = num_workers if num_workers is not None else os.cpu_count() // 2\n",
    "        self.hmi_path = hmi_path\n",
    "        self.aia_path = aia_path\n",
    "        self.eve_path = eve_path\n",
    "        self.batch_size = batch_size\n",
    "        self.components = components\n",
    "        self.components.sort()\n",
    "        self.wavelengths = wavelengths\n",
    "        self.wavelengths.sort()\n",
    "        self.ions = ions\n",
    "        self.ions.sort()\n",
    "        self.cadence = frequency\n",
    "        self.val_months = val_months\n",
    "        self.test_months = test_months\n",
    "        self.holdout_months = holdout_months\n",
    "        self.cache_dir = cache_dir\n",
    "\n",
    "        self.aia_data = zarr.group(zarr.DirectoryStore(self.aia_path))\n",
    "        self.eve_data = zarr.group(zarr.DirectoryStore(self.eve_path))\n",
    "        self.hmi_data = zarr.group(zarr.DirectoryStore(self.hmi_path))\n",
    "\n",
    "        self.train_months = [i for i in range(1,13) if i not in self.test_months + self.val_months + self.holdout_months]\n",
    "        self.training_years = [int(year) for year in self.aia_data.keys() if int(year) < 2015]\n",
    "\n",
    "        # Cache filenames\n",
    "        # if len(self.wavelengths) == 9:\n",
    "        #     wavelength_id = \"AIA_FULL\"\n",
    "        # else:\n",
    "        #     wavelength_id = \"_\".join(self.wavelengths)\n",
    "        \n",
    "        # if len(self.ions) == 38:\n",
    "        #     ions_id = \"EVE_FULL\"\n",
    "        # else:\n",
    "        #     ions_id = \"_\".join(ions).replace(\" \", \"_\")\n",
    "\n",
    "        # if len(self.components) == 3:\n",
    "        #     component_id = \"HMI_FULL\"\n",
    "        # else:\n",
    "        #     component_id = \"_\".join(self.components)\n",
    "\n",
    "        # self.cache_id = f\"{component_id}_{wavelength_id}_{ions_id}_{self.cadence}\"\n",
    "\n",
    "        # if \"small\" in self.aia_path: \n",
    "        #     self.cache_id += \"_small\"\n",
    "\n",
    "        # self.index_cache_filename = f\"{cache_dir}/aligndata_{self.cache_id}.csv\"\n",
    "        # self.normalizations_cache_filename = f\"{cache_dir}/normalizations_{self.cache_id}.json\"\n",
    "\n",
    "        # Temporal alignment of hmi, aia and eve data\n",
    "        self.aligndata = self.__aligntime()        \n",
    "        # self.normalizations = self.__calc_normalizations()\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "        output = \"\"\n",
    "        for k, v in self.__dict__.items():\n",
    "            output += f\"{k}: {v}\\n\"\n",
    "        return output\n",
    "\n",
    "\n",
    "    def __aligntime(self):\n",
    "        \"\"\"\n",
    "        This function extracts the common indexes across aia and eve datasets, considering potential missing values.\n",
    "        \"\"\"\n",
    "\n",
    "        # Check the cache\n",
    "        # if Path(self.index_cache_filename).exists():\n",
    "        #     print(f\"[* CACHE SYSTEM *] Found cached index data in {self.index_cache_filename}.\")\n",
    "        #     aligndata = pd.read_csv(self.index_cache_filename)\n",
    "        #     aligndata[\"Time\"] = pd.to_datetime(aligndata[\"Time\"])\n",
    "        #     aligndata.set_index(\"Time\", inplace=True)\n",
    "        #     return aligndata\n",
    "\n",
    "\n",
    "        # join_series = pd.DataFrame()\n",
    "        # for wavelength in self.wavelengths:\n",
    "        #     df_t_aia = pd.DataFrame()\n",
    "\n",
    "        #     for key in self.aia_data.keys():\n",
    "        #         aia_channel = self.aia_data[key][wavelength]\n",
    "\n",
    "        #         # Get observation time\n",
    "        #         t_obs_aia_channel = aia_channel.attrs['T_OBS']\n",
    "\n",
    "        #         df_tmp_aia = pd.DataFrame({'Time': pd.to_datetime(t_obs_aia_channel, format='mixed'), f\"idx_{wavelength}\": np.arange(0, len(t_obs_aia_channel))})\n",
    "        #         df_t_aia = pd.concat([df_t_aia, df_tmp_aia], ignore_index=True)\n",
    "\n",
    "        #     # Enforcing same datetime format\n",
    "        #     df_t_aia['Time'] = pd.to_datetime(df_t_aia['Time'], format='mixed').dt.tz_localize(None).dt.round(self.cadence).sort_values()\n",
    "        #     df_t_obs_aia = df_t_aia.drop_duplicates(subset='Time', keep='first').set_index('Time')\n",
    "\n",
    "        #     if wavelength == self.wavelengths[0]:\n",
    "        #         join_series = df_t_obs_aia\n",
    "        #     else:\n",
    "        #         join_series = join_series.join(df_t_obs_aia, how='inner')\n",
    "\n",
    "        print(f\"\\nData alignment calculation begin:\")\n",
    "        print(\"-\"*50)\n",
    "\n",
    "        # AIA\n",
    "        for i, wavelength in enumerate(self.wavelengths):\n",
    "            print(f\"Aligning AIA data for wavelength: {wavelength}\")\n",
    "            for j, year in enumerate(tqdm((self.training_years))): # EVE data only goes up to 2014\n",
    "                aia_channel = self.aia_data[year][wavelength]\n",
    "\n",
    "                # get observation time\n",
    "                t_obs_aia_channel = aia_channel.attrs['T_OBS'] \n",
    "                if j == 0:\n",
    "                    # transform to DataFrame\n",
    "                    # AIA\n",
    "                    df_t_aia = pd.DataFrame({'Time': pd.to_datetime(t_obs_aia_channel,format='mixed'), f'idx_{wavelength}': np.arange(0,len(t_obs_aia_channel))})\n",
    "\n",
    "                else:\n",
    "                    df_tmp_aia =pd.DataFrame({'Time': pd.to_datetime(t_obs_aia_channel, format='mixed'), f'idx_{wavelength}': np.arange(0,len(t_obs_aia_channel))})\n",
    "                    df_t_aia = pd.concat([df_t_aia, df_tmp_aia], ignore_index = True)\n",
    "\n",
    "            # Enforcing same datetime format\n",
    "            transform_datetime = lambda x: pd.to_datetime(x, format='mixed').strftime('%Y-%m-%d %H:%M:%S')\n",
    "            df_t_aia['Time'] = df_t_aia['Time'].apply(transform_datetime)\n",
    "            df_t_aia['Time'] = pd.to_datetime(df_t_aia['Time']).dt.tz_localize(None) # this is needed for timezone-naive type\n",
    "            df_t_aia['Time'] = df_t_aia['Time'].dt.round(self.cadence)\n",
    "            df_t_obs_aia = df_t_aia.drop_duplicates(subset='Time', keep='first') # removing potential duplicates derived by rounding\n",
    "            df_t_obs_aia.set_index('Time', inplace = True)\n",
    "\n",
    "            if i == 0:\n",
    "                join_series = df_t_obs_aia\n",
    "            else:\n",
    "                join_series = join_series.join(df_t_obs_aia, how='inner')\n",
    "\n",
    "        # EVE\n",
    "        print(f\"Aligning EVE data\")\n",
    "        df_t_eve = pd.DataFrame({'Time': pd.to_datetime(self.eve_data['MEGS-A']['Time'][:]), 'idx_eve': np.arange(0, len(self.eve_data['MEGS-A']['Time']))})\n",
    "        df_t_eve['Time'] = pd.to_datetime(df_t_eve['Time']).dt.round(self.cadence)\n",
    "        df_t_obs_eve = df_t_eve.drop_duplicates(subset='Time', keep='first').set_index('Time')\n",
    "        join_series = join_series.join(df_t_obs_eve, how='inner')\n",
    "\n",
    "        # remove missing eve data (missing values are labeled with negative values)\n",
    "        for ion in self.ions:\n",
    "            ion_data = self.eve_data['MEGS-A'][ion][:]\n",
    "            join_series = join_series.loc[ion_data[join_series['idx_eve']] > 0, :]\n",
    "\n",
    "\n",
    "        # HMI\n",
    "        for i, component in enumerate(self.components):\n",
    "            print(f\"Aligning HMI data for component: {component}\")\n",
    "            for j, year in enumerate(tqdm((self.training_years))): # EVE data only goes up to 2014\n",
    "                hmi_channel = self.hmi_data[year][component]\n",
    "\n",
    "                # get observation time\n",
    "                t_obs_hmi_channel_pre = hmi_channel.attrs['T_OBS'] \n",
    "                \n",
    "                # substitute characters\n",
    "                replacements = {'.': '-', '_': 'T','TTAI': '', '60':'59'}\n",
    "                t_obs_hmi_channel = []\n",
    "                for word in t_obs_hmi_channel_pre:\n",
    "                    for old_char, new_char in replacements.items():\n",
    "                        word = word.replace(old_char, new_char)\n",
    "                    t_obs_hmi_channel.append(word)\n",
    "\n",
    "                if j == 0:\n",
    "                    # transform to DataFrame\n",
    "                    # HMI\n",
    "                    df_t_hmi = pd.DataFrame({'Time': pd.to_datetime(t_obs_hmi_channel,format='mixed'), f'idx_{component}': np.arange(0,len(t_obs_hmi_channel))})\n",
    "\n",
    "                else:\n",
    "                    df_tmp_hmi =pd.DataFrame({'Time': pd.to_datetime(t_obs_hmi_channel, format='mixed'), f'idx_{component}': np.arange(0,len(t_obs_hmi_channel))})\n",
    "                    df_t_hmi = pd.concat([df_t_hmi, df_tmp_hmi], ignore_index = True)\n",
    "\n",
    "            # Enforcing same datetime format\n",
    "            transform_datetime = lambda x: pd.to_datetime(x, format='mixed').strftime('%Y-%m-%d %H:%M:%S')\n",
    "            df_t_hmi['Time'] = df_t_hmi['Time'].apply(transform_datetime)\n",
    "            df_t_hmi['Time'] = pd.to_datetime(df_t_hmi['Time']).dt.tz_localize(None) # this is needed for timezone-naive type\n",
    "            df_t_hmi['Time'] = df_t_hmi['Time'].dt.round(self.cadence)\n",
    "            df_t_obs_hmi = df_t_hmi.drop_duplicates(subset='Time', keep='first') # removing potential duplicates derived by rounding\n",
    "            df_t_obs_hmi.set_index('Time', inplace = True)\n",
    "\n",
    "\n",
    "            join_series = join_series.join(df_t_obs_hmi, how='inner')\n",
    "\n",
    "        join_series.sort_index(inplace=True)\n",
    "        \n",
    "        print(f\"Alignment completed with {join_series.shape[0]} samples.\")\n",
    "        #join_series.to_csv(self.index_cache_filename)        \n",
    "        return join_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZarrIrradianceDataModuleHMI(pl.LightningDataModule):\n",
    "    \"\"\" Loads paired data samples of AIA EUV images and EVE irradiance measures.\n",
    "\n",
    "    Note: Input data needs to be paired.\n",
    "    Parameters\n",
    "    ----------\n",
    "    aia_path: path to aia zarr file\n",
    "    eve_path: path to the EVE zarr data file\n",
    "    batch_size: batch size (default is 32)\n",
    "    num_workers: number of workers (needed for the training)\n",
    "    val_months: \n",
    "    \"\"\"\n",
    "    def __init__(self, hmi_path, aia_path, eve_path, components, wavelengths, ions, frequency, batch_size: int = 32, num_workers=None, val_months=[10,1], test_months=[11,12],  holdout_months=[], cache_dir=\"\"):\n",
    "\n",
    "        super().__init__()\n",
    "        self.num_workers = num_workers if num_workers is not None else os.cpu_count() // 2\n",
    "        self.hmi_path = hmi_path\n",
    "        self.aia_path = aia_path\n",
    "        self.eve_path = eve_path\n",
    "        self.batch_size = batch_size\n",
    "        self.components = components\n",
    "        self.components.sort()\n",
    "        self.wavelengths = wavelengths\n",
    "        self.wavelengths.sort()\n",
    "        self.ions = ions\n",
    "        self.ions.sort()\n",
    "        self.cadence = frequency\n",
    "        self.val_months = val_months\n",
    "        self.test_months = test_months\n",
    "        self.holdout_months = holdout_months\n",
    "        self.cache_dir = cache_dir\n",
    "\n",
    "        self.aia_data = zarr.group(zarr.DirectoryStore(self.aia_path))\n",
    "        self.eve_data = zarr.group(zarr.DirectoryStore(self.eve_path))\n",
    "        self.hmi_data = zarr.group(zarr.DirectoryStore(self.hmi_path))\n",
    "\n",
    "        self.train_months = [i for i in range(1,13) if i not in self.test_months + self.val_months + self.holdout_months]\n",
    "        self.training_years = [int(year) for year in self.aia_data.keys() if int(year) < 2015]\n",
    "\n",
    "        # Cache filenames\n",
    "        # if len(self.wavelengths) == 9:\n",
    "        #     wavelength_id = \"AIA_FULL\"\n",
    "        # else:\n",
    "        #     wavelength_id = \"_\".join(self.wavelengths)\n",
    "        \n",
    "        # if len(self.ions) == 38:\n",
    "        #     ions_id = \"EVE_FULL\"\n",
    "        # else:\n",
    "        #     ions_id = \"_\".join(ions).replace(\" \", \"_\")\n",
    "\n",
    "        # if len(self.components) == 3:\n",
    "        #     component_id = \"HMI_FULL\"\n",
    "        # else:\n",
    "        #     component_id = \"_\".join(self.components)\n",
    "\n",
    "        # self.cache_id = f\"{component_id}_{wavelength_id}_{ions_id}_{self.cadence}\"\n",
    "\n",
    "        # if \"small\" in self.aia_path: \n",
    "        #     self.cache_id += \"_small\"\n",
    "\n",
    "        # self.index_cache_filename = f\"{cache_dir}/aligndata_{self.cache_id}.csv\"\n",
    "        # self.normalizations_cache_filename = f\"{cache_dir}/normalizations_{self.cache_id}.json\"\n",
    "\n",
    "        # Temporal alignment of hmi, aia and eve data\n",
    "        self.aligndata = self.__aligntime()        \n",
    "        self.normalizations = self.__calc_normalizations()\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "        output = \"\"\n",
    "        for k, v in self.__dict__.items():\n",
    "            output += f\"{k}: {v}\\n\"\n",
    "        return output\n",
    "\n",
    "\n",
    "    def __aligntime(self):\n",
    "        \"\"\"\n",
    "        This function extracts the common indexes across aia and eve datasets, considering potential missing values.\n",
    "        \"\"\"\n",
    "\n",
    "        # Check the cache\n",
    "        # if Path(self.index_cache_filename).exists():\n",
    "        #     print(f\"[* CACHE SYSTEM *] Found cached index data in {self.index_cache_filename}.\")\n",
    "        #     aligndata = pd.read_csv(self.index_cache_filename)\n",
    "        #     aligndata[\"Time\"] = pd.to_datetime(aligndata[\"Time\"])\n",
    "        #     aligndata.set_index(\"Time\", inplace=True)\n",
    "        #     return aligndata\n",
    "\n",
    "\n",
    "        # join_series = pd.DataFrame()\n",
    "        # for wavelength in self.wavelengths:\n",
    "        #     df_t_aia = pd.DataFrame()\n",
    "\n",
    "        #     for key in self.aia_data.keys():\n",
    "        #         aia_channel = self.aia_data[key][wavelength]\n",
    "\n",
    "        #         # Get observation time\n",
    "        #         t_obs_aia_channel = aia_channel.attrs['T_OBS']\n",
    "\n",
    "        #         df_tmp_aia = pd.DataFrame({'Time': pd.to_datetime(t_obs_aia_channel, format='mixed'), f\"idx_{wavelength}\": np.arange(0, len(t_obs_aia_channel))})\n",
    "        #         df_t_aia = pd.concat([df_t_aia, df_tmp_aia], ignore_index=True)\n",
    "\n",
    "        #     # Enforcing same datetime format\n",
    "        #     df_t_aia['Time'] = pd.to_datetime(df_t_aia['Time'], format='mixed').dt.tz_localize(None).dt.round(self.cadence).sort_values()\n",
    "        #     df_t_obs_aia = df_t_aia.drop_duplicates(subset='Time', keep='first').set_index('Time')\n",
    "\n",
    "        #     if wavelength == self.wavelengths[0]:\n",
    "        #         join_series = df_t_obs_aia\n",
    "        #     else:\n",
    "        #         join_series = join_series.join(df_t_obs_aia, how='inner')\n",
    "\n",
    "        print(f\"\\nData alignment calculation begin:\")\n",
    "        print(\"-\"*50)\n",
    "\n",
    "        # AIA\n",
    "        for i, wavelength in enumerate(self.wavelengths):\n",
    "            print(f\"Aligning AIA data for wavelength: {wavelength}\")\n",
    "            for j, year in enumerate(tqdm((self.training_years))): # EVE data only goes up to 2014\n",
    "                aia_channel = self.aia_data[year][wavelength]\n",
    "\n",
    "                # get observation time\n",
    "                t_obs_aia_channel = aia_channel.attrs['T_OBS'] \n",
    "                if j == 0:\n",
    "                    # transform to DataFrame\n",
    "                    # AIA\n",
    "                    df_t_aia = pd.DataFrame({'Time': pd.to_datetime(t_obs_aia_channel,format='mixed'), f'idx_{wavelength}': np.arange(0,len(t_obs_aia_channel))})\n",
    "\n",
    "                else:\n",
    "                    df_tmp_aia =pd.DataFrame({'Time': pd.to_datetime(t_obs_aia_channel, format='mixed'), f'idx_{wavelength}': np.arange(0,len(t_obs_aia_channel))})\n",
    "                    df_t_aia = pd.concat([df_t_aia, df_tmp_aia], ignore_index = True)\n",
    "\n",
    "            # Enforcing same datetime format\n",
    "            transform_datetime = lambda x: pd.to_datetime(x, format='mixed').strftime('%Y-%m-%d %H:%M:%S')\n",
    "            df_t_aia['Time'] = df_t_aia['Time'].apply(transform_datetime)\n",
    "            df_t_aia['Time'] = pd.to_datetime(df_t_aia['Time']).dt.tz_localize(None) # this is needed for timezone-naive type\n",
    "            df_t_aia['Time'] = df_t_aia['Time'].dt.round(self.cadence)\n",
    "            df_t_obs_aia = df_t_aia.drop_duplicates(subset='Time', keep='first') # removing potential duplicates derived by rounding\n",
    "            df_t_obs_aia.set_index('Time', inplace = True)\n",
    "\n",
    "            if i == 0:\n",
    "                join_series = df_t_obs_aia\n",
    "            else:\n",
    "                join_series = join_series.join(df_t_obs_aia, how='inner')\n",
    "\n",
    "        # EVE\n",
    "        print(f\"Aligning EVE data\")\n",
    "        df_t_eve = pd.DataFrame({'Time': pd.to_datetime(self.eve_data['MEGS-A']['Time'][:]), 'idx_eve': np.arange(0, len(self.eve_data['MEGS-A']['Time']))})\n",
    "        df_t_eve['Time'] = pd.to_datetime(df_t_eve['Time']).dt.round(self.cadence)\n",
    "        df_t_obs_eve = df_t_eve.drop_duplicates(subset='Time', keep='first').set_index('Time')\n",
    "        join_series = join_series.join(df_t_obs_eve, how='inner')\n",
    "\n",
    "        # remove missing eve data (missing values are labeled with negative values)\n",
    "        for ion in self.ions:\n",
    "            ion_data = self.eve_data['MEGS-A'][ion][:]\n",
    "            join_series = join_series.loc[ion_data[join_series['idx_eve']] > 0, :]\n",
    "\n",
    "\n",
    "        # HMI \n",
    "        print(f\"Aligning HMI data\")\n",
    "\n",
    "        print(f\"Aligning HMI data for component: {self.components[0]}\")\n",
    "        for j, year in enumerate(tqdm((self.training_years))): # EVE data only goes up to 2014\n",
    "            \n",
    "            hmi_channel = self.hmi_data[year][self.components[0]]\n",
    "\n",
    "            # get observation time\n",
    "            t_obs_hmi_channel_pre = hmi_channel.attrs['T_OBS'] \n",
    "            \n",
    "            # substitute characters\n",
    "            replacements = {'.': '-', '_': 'T','TTAI': '', '60':'59'}\n",
    "            t_obs_hmi_channel = []\n",
    "            for word in t_obs_hmi_channel_pre:\n",
    "                for old_char, new_char in replacements.items():\n",
    "                    word = word.replace(old_char, new_char)\n",
    "                t_obs_hmi_channel.append(word)\n",
    "\n",
    "            if j == 0:\n",
    "                # transform to DataFrame\n",
    "                # HMI\n",
    "                df_t_hmi = pd.DataFrame({'Time': pd.to_datetime(t_obs_hmi_channel,format='mixed'), f'idx_{self.components[0]}': np.arange(0,len(t_obs_hmi_channel))})\n",
    "\n",
    "            else:\n",
    "                df_tmp_hmi =pd.DataFrame({'Time': pd.to_datetime(t_obs_hmi_channel, format='mixed'), f'idx_{self.components[0]}': np.arange(0,len(t_obs_hmi_channel))})\n",
    "                df_t_hmi = pd.concat([df_t_hmi, df_tmp_hmi], ignore_index = True)\n",
    "\n",
    "            # Enforcing same datetime format\n",
    "            transform_datetime = lambda x: pd.to_datetime(x, format='mixed').strftime('%Y-%m-%d %H:%M:%S')\n",
    "            df_t_hmi['Time'] = df_t_hmi['Time'].apply(transform_datetime)\n",
    "            df_t_hmi['Time'] = pd.to_datetime(df_t_hmi['Time']).dt.tz_localize(None) # this is needed for timezone-naive type\n",
    "            df_t_hmi['Time'] = df_t_hmi['Time'].dt.round(self.cadence)\n",
    "            df_t_obs_hmi = df_t_hmi.drop_duplicates(subset='Time', keep='first') # removing potential duplicates derived by rounding\n",
    "            df_t_obs_hmi.set_index('Time', inplace = True)\n",
    "\n",
    "\n",
    "        join_series = join_series.join(df_t_obs_hmi, how='inner')\n",
    "\n",
    "        join_series.sort_index(inplace=True)\n",
    "        \n",
    "        print(f\"Alignment completed with {join_series.shape[0]} samples.\")\n",
    "        #join_series.to_csv(self.index_cache_filename)        \n",
    "        \n",
    "        return join_series\n",
    "    \n",
    "\n",
    "    def __calc_normalizations(self):\n",
    "\n",
    "        #if Path(self.normalizations_cache_filename).exists():\n",
    "        #    print(f\"[* CACHE SYSTEM *] Found cached normalization data in {self.normalizations_cache_filename}.\")\n",
    "        #    with open(self.normalizations_cache_filename, \"r\") as json_file:\n",
    "        #        return json.load(json_file)\n",
    "        normalizations = {}\n",
    "        normalizations_align = self.aligndata.copy()\n",
    "        normalizations_align = normalizations_align[normalizations_align.index.month.isin(self.train_months)]\n",
    "\n",
    "        normalizations[\"HMI\"] = self.__calc_hmi_normalizations(normalizations_align)\n",
    "\n",
    "        return normalizations\n",
    "\n",
    "    def __calc_hmi_normalizations(self, normalizations_align) -> dict:\n",
    "        normalizations_hmi = {}\n",
    "\n",
    "        for component in self.components:\n",
    "            component_data = da.from_array(self.hmi_data[2010][component])\n",
    "\n",
    "            for year in self.training_years: # EVE data only goes up to 2014.                    \n",
    "                component_data_year = da.from_array(self.hmi_data[year][component])\n",
    "                component_data = da.concatenate([component_data, component_data_year], axis=0)\n",
    "\n",
    "            component_data = component_data[normalizations_align[f'idx_{self.components[0]}']]\n",
    "            \n",
    "            print(f\"\\nCalculating normalizations for component {component}:\")\n",
    "            print(\"-\"*50)\n",
    "\n",
    "            normalizations_hmi[component] = {}\n",
    "\n",
    "            print(f\"Sum:\")\n",
    "            with ProgressBar():\n",
    "                normalizations_hmi[component][\"sum\"] = component_data.sum().compute()\n",
    "\n",
    "            print(f\"Max Pixel Value:\")\n",
    "            with ProgressBar():\n",
    "                normalizations_hmi[component][\"max\"] = component_data.max().compute()\n",
    "\n",
    "            print(f\"Standard Deviation:\")\n",
    "            with ProgressBar():\n",
    "                normalizations_hmi[component][\"std\"] = component_data.std().compute()\n",
    "\n",
    "            print(f\"Skew:\")\n",
    "            with ProgressBar():\n",
    "                normalizations_hmi[component][\"skew\"] = stats.skew(component_data.flatten()).compute()\n",
    "\n",
    "            print(f\"Kurtosis:\")\n",
    "            with ProgressBar():\n",
    "                normalizations_hmi[component][\"kurtosis\"] = stats.kurtosis(component_data.flatten()).compute()\n",
    "\n",
    "            normalizations_hmi[component][\"image_count\"] = component_data.shape[0]\n",
    "            normalizations_hmi[component][\"pixel_count\"] = component_data.shape[0] * component_data.shape[1] * component_data.shape[2]\n",
    "            normalizations_hmi[component][\"mean\"] = normalizations_hmi[component][\"sum\"] / normalizations_hmi[component][\"pixel_count\"]\n",
    "            \n",
    "            \n",
    "        return normalizations_hmi\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmi_path = \"/mnt/sdomlv2_hmi/sdomlv2_hmi.zarr\"\n",
    "aia_path = \"/mnt/sdomlv2_full/sdomlv2.zarr\"\n",
    "eve_path = \"/mnt/sdomlv2_small/sdomlv2_eve.zarr\"\n",
    "components = [\"Bx\", \"By\", \"Bz\"]\n",
    "wavelengths = [\"94A\",]\n",
    "ions = [\"C III\"]\n",
    "frequency = \"12min\"\n",
    "batch_size = 32\n",
    "\n",
    "test = ZarrIrradianceDataModuleHMI(hmi_path, aia_path, eve_path, components, wavelengths, ions, frequency, batch_size, num_workers=None, val_months=[10,1], test_months=[11,12],  holdout_months=[], cache_dir=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_list = time\n",
    "replacements = {'.': '-', '_': 'T','TTAI': '', '60':'59'}\n",
    "\n",
    "new_list = []\n",
    "for word in original_list:\n",
    "    for old_char, new_char in replacements.items():\n",
    "        word = word.replace(old_char, new_char)\n",
    "    new_list.append(word)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daniel-hmieve",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
