{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from pathlib import Path\n",
                "\n",
                "import pytorch_lightning as pl\n",
                "import torch\n",
                "import wandb\n",
                "from sdofm import utils\n",
                "from sdofm.datasets import SDOMLDataModule\n",
                "from sdofm.benchmarks import reconstruction as bench_recon\n",
                "from sdofm.constants import ALL_WAVELENGTHS\n",
                "\n",
                "from sdofm.pretraining import MAE"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [],
            "source": [
                "import omegaconf\n",
                "\n",
                "cfg = omegaconf.OmegaConf.load(\"../experiments/pretrain_tiny_mae.yaml\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[* CACHE SYSTEM *] Found cached index data in /mnt/sdoml/cache/aligndata_AIA_FULL_12min.csv.\n",
                        "[* CACHE SYSTEM *] Found cached normalization data in /mnt/sdoml/cache/normalizations_AIA_FULL_12min.json.\n",
                        "[* CACHE SYSTEM *] Found cached HMI mask data in /mnt/sdoml/cache/hmi_mask_512x512.npy.\n"
                    ]
                }
            ],
            "source": [
                "data_module = SDOMLDataModule(\n",
                "# hmi_path=os.path.join(\n",
                "#      cfg.data.sdoml.base_directory,  cfg.data.sdoml.sub_directory.hmi\n",
                "# ),\n",
                "hmi_path=None,\n",
                "aia_path=os.path.join(\n",
                "        cfg.data.sdoml.base_directory,\n",
                "        cfg.data.sdoml.sub_directory.aia,\n",
                "),\n",
                "eve_path=None,\n",
                "components= cfg.data.sdoml.components,\n",
                "wavelengths= cfg.data.sdoml.wavelengths,\n",
                "ions= cfg.data.sdoml.ions,\n",
                "frequency= cfg.data.sdoml.frequency,\n",
                "batch_size= cfg.model.opt.batch_size,\n",
                "num_workers= cfg.data.num_workers,\n",
                "val_months= cfg.data.month_splits.val,\n",
                "test_months= cfg.data.month_splits.test,\n",
                "holdout_months= cfg.data.month_splits.holdout,\n",
                "cache_dir=os.path.join(\n",
                "        cfg.data.sdoml.base_directory,\n",
                "        cfg.data.sdoml.sub_directory.cache,\n",
                "),\n",
                "min_date=cfg.data.min_date,\n",
                "max_date=cfg.data.max_date,\n",
                "num_frames=cfg.model.mae.num_frames,\n",
                ")\n",
                "data_module.setup()\n",
                "\n",
                "model = MAE(\n",
                "**cfg.model.mae,\n",
                "optimiser=cfg.model.opt.optimiser,\n",
                "lr=cfg.model.opt.learning_rate,\n",
                "weight_decay=cfg.model.opt.weight_decay,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [],
            "source": [
                "x = next(iter(data_module.train_dataloader()))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "torch.Size([4, 9, 2, 512, 512])"
                        ]
                    },
                    "execution_count": 23,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "x.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [],
            "source": [
                "loss, x_hat, mask = model.autoencoder(x)\n",
                "x_hat = model.autoencoder.unpatchify(x_hat)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(torch.Size([4, 9, 2, 512, 512]), torch.Size([4, 9, 2, 512, 512]))"
                        ]
                    },
                    "execution_count": 25,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "x_hat.shape, x.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {},
            "outputs": [],
            "source": [
                "validation_metrics = []\n",
                "for i in range(x.shape[2]):\n",
                "    validation_metrics.append(bench_recon.get_metrics(x[i,:,0,:,:], x_hat[i,:,0,:,:], ALL_WAVELENGTHS))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "metadata": {},
            "outputs": [],
            "source": [
                "merged_metrics = bench_recon.merge_metrics(validation_metrics)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [],
            "source": [
                "batch_metrics = bench_recon.mean_metrics(merged_metrics)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'131A': {'flux_difference': -1.4445356768376798,\n",
                            "  'ppe10s': 0.012109756469726562,\n",
                            "  'ppe50s': 0.544952392578125,\n",
                            "  'rms_contrast_measure': 0.4743000500586574,\n",
                            "  'pixel_correlation': -0.017537385392165428,\n",
                            "  'rmse_intensity': 0.7930678055708583},\n",
                            " '1600A': {'flux_difference': -1.0408771465211641,\n",
                            "  'ppe10s': 0.4959297180175781,\n",
                            "  'ppe50s': 0.5631198883056641,\n",
                            "  'rms_contrast_measure': 0.6043902129714565,\n",
                            "  'pixel_correlation': -0.022836154032107474,\n",
                            "  'rmse_intensity': 0.8877159866519266},\n",
                            " '1700A': {'flux_difference': -0.9620249346126075,\n",
                            "  'ppe10s': 0.4963951110839844,\n",
                            "  'ppe50s': 0.5646400451660156,\n",
                            "  'rms_contrast_measure': 0.5965223285931959,\n",
                            "  'pixel_correlation': 0.020996891555964937,\n",
                            "  'rmse_intensity': 0.8857073985798133},\n",
                            " '171A': {'flux_difference': -1.076724,\n",
                            "  'ppe10s': 0.034648895263671875,\n",
                            "  'ppe50s': 0.18700599670410156,\n",
                            "  'rms_contrast_measure': 0.69384634,\n",
                            "  'pixel_correlation': 0.0018008068821008419,\n",
                            "  'rmse_intensity': 1.0837147},\n",
                            " '193A': {'flux_difference': -0.9223758,\n",
                            "  'ppe10s': 0.038593292236328125,\n",
                            "  'ppe50s': 0.18694496154785156,\n",
                            "  'rms_contrast_measure': 0.66977334,\n",
                            "  'pixel_correlation': 0.002231161256166238,\n",
                            "  'rmse_intensity': 0.99985516},\n",
                            " '211A': {'flux_difference': -0.98467946,\n",
                            "  'ppe10s': 0.034076690673828125,\n",
                            "  'ppe50s': 0.16853713989257812,\n",
                            "  'rms_contrast_measure': 0.69447696,\n",
                            "  'pixel_correlation': 0.001023899050380674,\n",
                            "  'rmse_intensity': 1.0418239},\n",
                            " '304A': {'flux_difference': -1.2229435,\n",
                            "  'ppe10s': 0.033954620361328125,\n",
                            "  'ppe50s': 0.1823272705078125,\n",
                            "  'rms_contrast_measure': 0.5685947,\n",
                            "  'pixel_correlation': -0.003048795725341686,\n",
                            "  'rmse_intensity': 1.1780827},\n",
                            " '335A': {'flux_difference': -0.9360851,\n",
                            "  'ppe10s': 0.034015655517578125,\n",
                            "  'ppe50s': 0.168060302734375,\n",
                            "  'rms_contrast_measure': 0.591371,\n",
                            "  'pixel_correlation': 0.0018100730002986404,\n",
                            "  'rmse_intensity': 1.0234611},\n",
                            " '94A': {'flux_difference': -0.8983707,\n",
                            "  'ppe10s': 0.03423309326171875,\n",
                            "  'ppe50s': 0.16687774658203125,\n",
                            "  'rms_contrast_measure': 0.59124833,\n",
                            "  'pixel_correlation': -0.0009895150087396258,\n",
                            "  'rmse_intensity': 0.82288545}}"
                        ]
                    },
                    "execution_count": 36,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "batch_metrics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "\n",
                "plt.imshow(rbg_image_batch[0, 0, 0, :, :].cpu().numpy(), cmap=\"gray\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "mask = data_module.hmi_mask\n",
                "print(mask.shape)\n",
                "plt.imshow(mask.cpu().numpy(), cmap=\"gray\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sdofm.utils import get_1d_sincos_pos_embed_from_grid, get_3d_sincos_pos_embed\n",
                "\n",
                "embed_dim = 128\n",
                "num_frames = 1\n",
                "tubelet_size = 1\n",
                "img_size = (512, 512)\n",
                "patch_size = (16, 16)\n",
                "grid_size = (\n",
                "    num_frames // tubelet_size,\n",
                "    img_size[0] // patch_size[0],\n",
                "    img_size[1] // patch_size[1],\n",
                ")\n",
                "num_patches = grid_size[0] * grid_size[1] * grid_size[2]\n",
                "pos_embed_zeros = torch.zeros(1, num_patches + 1, embed_dim)\n",
                "pos_embed = get_3d_sincos_pos_embed(\n",
                "    pos_embed_zeros.shape[-1], grid_size, cls_token=False\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "single_image_batch.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "mask.shape\n",
                "a = np.repeat(mask[:, :, np.newaxis], 9, axis=2)\n",
                "b = np.repeat(a[:, :, :, np.newaxis], 1, axis=3)\n",
                "c = np.repeat(b[:, :, :, :, np.newaxis], 1, axis=4)\n",
                "# c.shape\n",
                "d = torch.Tensor(np.transpose(c, axes=(3, 2, 4, 0, 1))).to(dtype=torch.float)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "mask.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "single_image_batch[0, 0]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "patch_embed = PatchEmbed(512, 16, 1, 1, 9, 128, flatten=True)\n",
                "x = patch_embed(d)\n",
                "x.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "indices = np.arange(32 * 32).reshape(32, 32).astype(np.int64)\n",
                "ai = np.repeat(indices[:, :, np.newaxis], 128, axis=2)\n",
                "bi = np.repeat(ai[:, :, :, np.newaxis], 1, axis=3)\n",
                "ci = np.repeat(bi[:, :, :, :, np.newaxis], 1, axis=4)\n",
                "di = torch.Tensor(np.transpose(ci, axes=(3, 2, 4, 0, 1)))  # .to(dtype=torch.float)\n",
                "di.shape\n",
                "fi = di.flatten(2).transpose(1, 2)\n",
                "fi.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.scatter(x=range(1024), y=fi[0, :, 0].detach().numpy())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "15 * 15"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fi[0, :, 0].max()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.imshow(x[0, 0, 0, :, :].detach().numpy())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.imshow(x[0, :, :].detach().numpy(), aspect=\"auto\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pos_embed = get_3d_sincos_pos_embed(\n",
                "    pos_embed.shape[-1], patch_embed.grid_size, cls_token=False\n",
                ")\n",
                "pos_embed = torch.from_numpy(pos_embed).float().unsqueeze(0)\n",
                "pos_embed.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "patchified.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "patch_embed.grid_size[1]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import astropy.units as u\n",
                "from astropy.coordinates import SkyCoord\n",
                "import sunpy.data.sample\n",
                "import sunpy.map\n",
                "from sunpy.coordinates.frames import HeliographicStonyhurst\n",
                "\n",
                "aiamap = sunpy.map.Map(\n",
                "    sunpy.data.sample.AIA_171_IMAGE\n",
                ")  # example image is loaded at 1024x1024\n",
                "\n",
                "\n",
                "def stonyhurst_to_patch_index(lat, lon):\n",
                "    # Heliographic Stonyhurst coordinates to patch index\n",
                "    # lat, lon = 15.73, 0\n",
                "    coord = SkyCoord(lat * u.deg, lon * u.deg, frame=HeliographicStonyhurst)\n",
                "    x, y = aiamap.wcs.world_to_pixel(coord)  # (x, y) in pixels\n",
                "    x, y = x / 2 // patch_embed.patch_size[0], y / 2 // patch_embed.patch_size[0]\n",
                "    return np.array([x, y])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "middle_patch = stonyhurst_to_patch_index(0, 0)\n",
                "middle_patch"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "r1_patch = stonyhurst_to_patch_index(0, -60)[1]\n",
                "r2_patch = stonyhurst_to_patch_index(0, 60)[1]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "stonyhurst_to_patch_index(60, 0)\n",
                "# r2_patch = stonyhurst_to_patch_index(0, 60)[1]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "mean_patch = (\n",
                "    abs(\n",
                "        (stonyhurst_to_patch_index(15.73, 0) - stonyhurst_to_patch_index(0, 0))\n",
                "        + abs(stonyhurst_to_patch_index(-15.73, 0) - stonyhurst_to_patch_index(0, 0))\n",
                "    )\n",
                ")[0] / 2\n",
                "mean_patch"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "std_patch = (stonyhurst_to_patch_index(6.14, 0) - stonyhurst_to_patch_index(0, 0))[0]\n",
                "std_patch"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# torch.uniform(0, 32)\n",
                "# x = torch.distributions.uniform.Uniform(0,32).sample((1024,))\n",
                "# x\n",
                "\n",
                "# get uniform random numbers between [r1_patch, r2_patch]\n",
                "# (r1 - r2) * torch.rand(a, b) + r2\n",
                "# random_lons = torch.floor( (r1_patch - r2_patch ) * torch.rand((1024,)) + r2_patch ).to(dtype=torch.uint8)\n",
                "N = 2\n",
                "random_lons = torch.floor((r1_patch - r2_patch) * torch.rand((N, 1024)) + r2_patch).to(\n",
                "    dtype=torch.uint8\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "normal_lats = torch.floor(torch.normal(mean_patch, std_patch, size=(N, 1024)))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "random_hemisphere = torch.floor(torch.rand((N, 1024)) * (2)).to(dtype=torch.int8)\n",
                "random_hemisphere[random_hemisphere == 0] = -1\n",
                "random_lats = random_hemisphere * normal_lats"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "random_lons.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.scatter(random_lons[0, :], random_lats[0, :] + 15)\n",
                "plt.title(\"Per-hemisphere lat-normally lon-uniformly distributed patch locations\")\n",
                "plt.xlabel(\"Patch index (solar longitude)\")\n",
                "plt.ylabel(\"Patch index (solar latitude)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "N = 1\n",
                "L = 1024\n",
                "noise = torch.rand(N, L)  # noise in [0, 1]\n",
                "\n",
                "# sort noise for each sample\n",
                "ids_shuffle = torch.argsort(noise, dim=1)  # ascend: small is keep, large is remove\n",
                "ids_restore = torch.argsort(ids_shuffle, dim=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ids_shuffle = random_lons * (random_lats + 15)\n",
                "ids_shuffle.to(dtype=torch.int16)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "torch.argsort(ids_shuffle, dim=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ids_shuffle"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "32 * 32"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "15 - 12\n",
                "19 - 15\n",
                "# patch_idx = x*y\n",
                "\n",
                "# Patch index to embedding index\n",
                "# frame_number"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "torch.normal(3.5)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "\n",
                "# Patch number to embedding index\n",
                "indices = np.arange(32 * 32).reshape(32, 32).astype(np.int64)\n",
                "ai = np.repeat(indices[:, :, np.newaxis], 128, axis=2)\n",
                "bi = np.repeat(ai[:, :, :, np.newaxis], 1, axis=3)\n",
                "ci = np.repeat(bi[:, :, :, :, np.newaxis], 1, axis=4)\n",
                "di = torch.Tensor(np.transpose(ci, axes=(3, 2, 4, 0, 1)))  # .to(dtype=torch.float)\n",
                "di.shape\n",
                "fi = di.flatten(2).transpose(1, 2)\n",
                "fi.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "torch.where(fi[0, :, 0] == patch_idx)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "p = patch_embed.patch_size[0]\n",
                "num_p = patch_embed.img_size[0] // p\n",
                "tub = patch_embed.tubelet_size\n",
                "imgs = rearrange(\n",
                "    pos_embed,\n",
                "    \"b (t h w) (tub p q c) -> b c (t tub) (h p) (w q)\",\n",
                "    h=num_p,\n",
                "    w=num_p,\n",
                "    tub=tub,\n",
                "    p=p,\n",
                "    q=p,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "num_p"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.imshow(imgs[0, 0, 0, :, :].cpu().numpy(), cmap=\"gray\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "\n",
                "b = np.repeat(mask[:, :, np.newaxis], 4, axis=2)\n",
                "b = np.transpose(b, axes=[2, 0, 1])\n",
                "(b[0, :, :] == b[1, :, :])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sdofm.models.samae3d import PatchEmbed\n",
                "\n",
                "patch_embed = PatchEmbed(512, 16, 1, 1, 9, 128, flatten=False)\n",
                "\n",
                "nn.Conv3d(\n",
                "    in_chans=3,\n",
                "    embed_dim=128,\n",
                "    kernel_size=(1, 16, 16),\n",
                "    stride=(1, 16, 16),\n",
                "    bias=True,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "patch_embed(image_batch).shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "patch_embed.proj.weight.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "16 * 32"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The MaskedConv3D is a standard Conv3D with a binary mask applied on sampling locations that shouldn't contribute to the learning process. Whilst in theory a Conv3D could be written to take non-cubic input voxels this should achieve the same effect. The standard torch `nn.Conv3d` is modified such that \n",
                "\n",
                "In the simplest case, the output value of the layer with input size $(N, C_{in},D,H,W)$, output $(N, C_{out},D_{out},H_{out},W_{out})$, and logical mask $M$ can be described as:\n",
                "\n",
                "$$out(N_i, C_{out_j}) = bias(C_{out_j})+ \\sum_{C_{in}-1}^{k=0} M*weight(C_{out_j}, k) \\star input(N_i, k)$$"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "sdofm",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.14"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
